{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3260f273-6e59-41a1-8897-d0f91fdee373",
   "metadata": {},
   "source": [
    "# DSCI591 Data Collection\n",
    "## COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0393b1b-4ab4-4024-825f-1e3608a7cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "import os\n",
    "from os import path\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gamma\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf03f8a-1847-440c-ade2-c326323520cb",
   "metadata": {},
   "source": [
    "### Helper Methods from the C3.ai Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ea08cf-a154-40ab-adfb-85c9e60dff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_json(typename, api, body):\n",
    "    \"\"\"\n",
    "    read_data_json directly accesses the C3.ai COVID-19 Data Lake APIs using the requests library, \n",
    "    and returns the response as a JSON, raising an error if the call fails for any reason.\n",
    "    ------\n",
    "    typename: The type you want to access, i.e. 'OutbreakLocation', 'LineListRecord', 'BiblioEntry', etc.\n",
    "    api: The API you want to access, either 'fetch' or 'evalmetrics'.\n",
    "    body: The spec you want to pass. For examples, see the API documentation.\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        \"https://api.c3.ai/covid/api/1/\" + typename + \"/\" + api, \n",
    "        json = body, \n",
    "        headers = {\n",
    "            'Accept' : 'application/json', \n",
    "            'Content-Type' : 'application/json'\n",
    "        }\n",
    "    )\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def fetch(typename, body, get_all = False, remove_meta = True):\n",
    "    \"\"\"\n",
    "    fetch accesses the Data Lake using read_data_json, and converts the response into a Pandas dataframe. \n",
    "    fetch is used for all non-timeseries data in the Data Lake, and will call read_data as many times \n",
    "    as required to access all of the relevant data for a given typename and body.\n",
    "    ------\n",
    "    typename: The type you want to access, i.e. 'OutbreakLocation', 'LineListRecord', 'BiblioEntry', etc.\n",
    "    body: The spec you want to pass. For examples, see the API documentation.\n",
    "    get_all: If True, get all records and ignore any limit argument passed in the body. If False, use the limit argument passed in the body. The default is False.\n",
    "    remove_meta: If True, remove metadata about each record. If False, include it. The default is True.\n",
    "    \"\"\"\n",
    "    if get_all:\n",
    "        has_more = True\n",
    "        offset = 0\n",
    "        limit = 2000\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        while has_more:\n",
    "            body['spec'].update(limit = limit, offset = offset)\n",
    "            response_json = read_data_json(typename, 'fetch', body)\n",
    "            new_df = pd.json_normalize(response_json['objs'])\n",
    "            df = df.append(new_df)\n",
    "            has_more = response_json['hasMore']\n",
    "            offset += limit\n",
    "            \n",
    "    else:\n",
    "        response_json = read_data_json(typename, 'fetch', body)\n",
    "        df = pd.json_normalize(response_json['objs'])\n",
    "        \n",
    "    if remove_meta:\n",
    "        df = df.drop(columns = [c for c in df.columns if ('meta' in c) | ('version' in c)])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def evalmetrics(typename, body, remove_meta = True):\n",
    "    \"\"\"\n",
    "    evalmetrics accesses the Data Lake using read_data_json, and converts the response into a Pandas dataframe.\n",
    "    evalmetrics is used for all timeseries data in the Data Lake.\n",
    "    ------\n",
    "    typename: The type you want to access, i.e. 'OutbreakLocation', 'LineListRecord', 'BiblioEntry', etc.\n",
    "    body: The spec you want to pass. For examples, see the API documentation.\n",
    "    remove_meta: If True, remove metadata about each record. If False, include it. The default is True.\n",
    "    \"\"\"\n",
    "    response_json = read_data_json(typename, 'evalmetrics', body)\n",
    "    df = pd.json_normalize(response_json['result'])\n",
    "    \n",
    "    # get the useful data out\n",
    "    df = df.apply(pd.Series.explode)\n",
    "    if remove_meta:\n",
    "        df = df.filter(regex = 'dates|data|missing')\n",
    "    \n",
    "    # only keep one date column\n",
    "    date_cols = [col for col in df.columns if 'dates' in col]\n",
    "    keep_cols =  date_cols[:1] + [col for col in df.columns if 'dates' not in col]\n",
    "    df = df.filter(items = keep_cols).rename(columns = {date_cols[0] : \"dates\"})\n",
    "    df[\"dates\"] = pd.to_datetime(df[\"dates\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bf714-f256-423d-ac70-676bed408266",
   "metadata": {},
   "source": [
    "#### Streamlined request for single item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88336d87-3ce4-4238-97d6-6aae3a594531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_one(typename: str, body: dict, objs_only=True) -> dict:\n",
    "    \"\"\"\n",
    "    Returns JSON output from single API call\n",
    "    \n",
    "    Args:\n",
    "        typename: the C3.ai type name\n",
    "        body: the body of the request\n",
    "        objs_only: if True, remove the metadata and just returns the objects\n",
    "        \n",
    "    Returns:\n",
    "        JSON response as dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    response = read_data_json(typename, 'fetch', body)\n",
    "    if objs_only:\n",
    "        for r in response['objs']:\n",
    "            if 'meta' in r.keys():\n",
    "                del(r['meta'])\n",
    "                \n",
    "        return response['objs']\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8737a-1346-48d0-b81a-fabae73e65f1",
   "metadata": {},
   "source": [
    "### Load the location codes for the US into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21596af8-4fe3-4363-a609-83e643c8694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_us_locations(file_name='./config/C3-ai-Location-IDs.xlsx'): \n",
    "    \"\"\" Loads all US counties from C3 ai spreadsheet \n",
    "    \n",
    "    Args:\n",
    "        file_name: the name of the spreadsheet\n",
    "        \n",
    "    Returns:\n",
    "        Pandas dataframe with the results\n",
    "    \n",
    "    \"\"\"\n",
    "                     \n",
    "    locations = pd.read_excel(path.join('.', file_name), sheet_name='County IDs', header=2)\n",
    "    us_locations = locations[locations.Country=='United States']\n",
    "    \n",
    "    return us_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40df2a6-6966-4196-baba-f79cb07871d9",
   "metadata": {},
   "source": [
    "### Get the basic population data for each of the 3429 counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ea48d1-7c01-462c-a414-bdbbadbd0e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hospitalIcuBeds': 6,\n",
       "  'hospitalStaffedBeds': 55,\n",
       "  'hospitalLicensedBeds': 85,\n",
       "  'latestTotalPopulation': 55869.0,\n",
       "  'populationOfAllChildren': 55869.0,\n",
       "  'latestLaborForce': 25541,\n",
       "  'latestEmployedPopulation': 24953,\n",
       "  'latestUnemployedPopulation': 588,\n",
       "  'latestUnemploymentRate': 2.302180807329392,\n",
       "  'laborForceOfAllChildren': 25541,\n",
       "  'locationType': 'county',\n",
       "  'populationCDS': 55869,\n",
       "  'location': {'value': {'id': 'Autauga_Alabama_UnitedStates'},\n",
       "   'timestamp': '2021-08-04T00:00:00Z'},\n",
       "  'fips': {'id': '01001'},\n",
       "  'id': 'Autauga_Alabama_UnitedStates',\n",
       "  'name': 'Autauga',\n",
       "  'version': 38863297,\n",
       "  'typeIdent': 'EP_LOC'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_outbreaklocation_body(county_id: str) -> dict:\n",
    "    \"\"\" Forms the request body for a count for the outbreak location API \n",
    "    \n",
    "    Args:\n",
    "        count_id: the ID for the County\n",
    "    \n",
    "    Returns:\n",
    "        The request body\n",
    "    \n",
    "    \"\"\"\n",
    "    return {\n",
    "              \"spec\": {\n",
    "                \"filter\": f\"id == '{county_id}'\"\n",
    "              }\n",
    "}\n",
    "\n",
    "fetch_one('outbreaklocation', make_outbreaklocation_body('Autauga_Alabama_UnitedStates'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bac429b-e05a-4666-a6ef-a4b485f9cad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalIcuBeds</th>\n",
       "      <th>hospitalStaffedBeds</th>\n",
       "      <th>hospitalLicensedBeds</th>\n",
       "      <th>latestTotalPopulation</th>\n",
       "      <th>location</th>\n",
       "      <th>fips</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>typeIdent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Autauga_Alabama_UnitedStates</th>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55869.0</td>\n",
       "      <td>{'value': {'id': 'Autauga_Alabama_UnitedStates...</td>\n",
       "      <td>{'id': '01001'}</td>\n",
       "      <td>Autauga_Alabama_UnitedStates</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>3735560.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin_Alabama_UnitedStates</th>\n",
       "      <td>51.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>223234.0</td>\n",
       "      <td>{'value': {'id': 'Baldwin_Alabama_UnitedStates...</td>\n",
       "      <td>{'id': '01003'}</td>\n",
       "      <td>Baldwin_Alabama_UnitedStates</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>3801096.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour_Alabama_UnitedStates</th>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>24686.0</td>\n",
       "      <td>{'value': {'id': 'Barbour_Alabama_UnitedStates...</td>\n",
       "      <td>{'id': '01005'}</td>\n",
       "      <td>Barbour_Alabama_UnitedStates</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>3801096.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb_Alabama_UnitedStates</th>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22394.0</td>\n",
       "      <td>{'value': {'id': 'Bibb_Alabama_UnitedStates'},...</td>\n",
       "      <td>{'id': '01007'}</td>\n",
       "      <td>Bibb_Alabama_UnitedStates</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>3997704.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount_Alabama_UnitedStates</th>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57826.0</td>\n",
       "      <td>{'value': {'id': 'Blount_Alabama_UnitedStates'...</td>\n",
       "      <td>{'id': '01009'}</td>\n",
       "      <td>Blount_Alabama_UnitedStates</td>\n",
       "      <td>Blount</td>\n",
       "      <td>3801096.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unassigned_Wisconsin_UnitedStates</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'value': {'id': 'Unassigned_Wisconsin_UnitedS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unassigned_Wisconsin_UnitedStates</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>3080195.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unassigned_Wyoming_UnitedStates</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'value': {'id': 'Unassigned_Wyoming_UnitedSta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unassigned_Wyoming_UnitedStates</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>3080201.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unassigned_Guam_UnitedStates</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unassigned_Guam_UnitedStates</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unassigned_NorthernMarianaIslands_UnitedStates</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'value': {'id': 'Unassigned_NorthernMarianaIs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unassigned_NorthernMarianaIslands_UnitedStates</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>458755.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unassigned_PuertoRico_UnitedStates</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unassigned_PuertoRico_UnitedStates</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EP_LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3249 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hospitalIcuBeds  \\\n",
       "Autauga_Alabama_UnitedStates                                6.0   \n",
       "Baldwin_Alabama_UnitedStates                               51.0   \n",
       "Barbour_Alabama_UnitedStates                                5.0   \n",
       "Bibb_Alabama_UnitedStates                                   4.0   \n",
       "Blount_Alabama_UnitedStates                                 6.0   \n",
       "...                                                         ...   \n",
       "Unassigned_Wisconsin_UnitedStates                           NaN   \n",
       "Unassigned_Wyoming_UnitedStates                             NaN   \n",
       "Unassigned_Guam_UnitedStates                                NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates              NaN   \n",
       "Unassigned_PuertoRico_UnitedStates                          NaN   \n",
       "\n",
       "                                                hospitalStaffedBeds  \\\n",
       "Autauga_Alabama_UnitedStates                                   55.0   \n",
       "Baldwin_Alabama_UnitedStates                                  362.0   \n",
       "Barbour_Alabama_UnitedStates                                   30.0   \n",
       "Bibb_Alabama_UnitedStates                                      25.0   \n",
       "Blount_Alabama_UnitedStates                                    25.0   \n",
       "...                                                             ...   \n",
       "Unassigned_Wisconsin_UnitedStates                               NaN   \n",
       "Unassigned_Wyoming_UnitedStates                                 NaN   \n",
       "Unassigned_Guam_UnitedStates                                    NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates                  NaN   \n",
       "Unassigned_PuertoRico_UnitedStates                              NaN   \n",
       "\n",
       "                                                hospitalLicensedBeds  \\\n",
       "Autauga_Alabama_UnitedStates                                    85.0   \n",
       "Baldwin_Alabama_UnitedStates                                   386.0   \n",
       "Barbour_Alabama_UnitedStates                                    74.0   \n",
       "Bibb_Alabama_UnitedStates                                       35.0   \n",
       "Blount_Alabama_UnitedStates                                     25.0   \n",
       "...                                                              ...   \n",
       "Unassigned_Wisconsin_UnitedStates                                NaN   \n",
       "Unassigned_Wyoming_UnitedStates                                  NaN   \n",
       "Unassigned_Guam_UnitedStates                                     NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates                   NaN   \n",
       "Unassigned_PuertoRico_UnitedStates                               NaN   \n",
       "\n",
       "                                                latestTotalPopulation  \\\n",
       "Autauga_Alabama_UnitedStates                                  55869.0   \n",
       "Baldwin_Alabama_UnitedStates                                 223234.0   \n",
       "Barbour_Alabama_UnitedStates                                  24686.0   \n",
       "Bibb_Alabama_UnitedStates                                     22394.0   \n",
       "Blount_Alabama_UnitedStates                                   57826.0   \n",
       "...                                                               ...   \n",
       "Unassigned_Wisconsin_UnitedStates                                 NaN   \n",
       "Unassigned_Wyoming_UnitedStates                                   NaN   \n",
       "Unassigned_Guam_UnitedStates                                      NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates                    NaN   \n",
       "Unassigned_PuertoRico_UnitedStates                                NaN   \n",
       "\n",
       "                                                                                         location  \\\n",
       "Autauga_Alabama_UnitedStates                    {'value': {'id': 'Autauga_Alabama_UnitedStates...   \n",
       "Baldwin_Alabama_UnitedStates                    {'value': {'id': 'Baldwin_Alabama_UnitedStates...   \n",
       "Barbour_Alabama_UnitedStates                    {'value': {'id': 'Barbour_Alabama_UnitedStates...   \n",
       "Bibb_Alabama_UnitedStates                       {'value': {'id': 'Bibb_Alabama_UnitedStates'},...   \n",
       "Blount_Alabama_UnitedStates                     {'value': {'id': 'Blount_Alabama_UnitedStates'...   \n",
       "...                                                                                           ...   \n",
       "Unassigned_Wisconsin_UnitedStates               {'value': {'id': 'Unassigned_Wisconsin_UnitedS...   \n",
       "Unassigned_Wyoming_UnitedStates                 {'value': {'id': 'Unassigned_Wyoming_UnitedSta...   \n",
       "Unassigned_Guam_UnitedStates                                                                  NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates  {'value': {'id': 'Unassigned_NorthernMarianaIs...   \n",
       "Unassigned_PuertoRico_UnitedStates                                                            NaN   \n",
       "\n",
       "                                                           fips  \\\n",
       "Autauga_Alabama_UnitedStates                    {'id': '01001'}   \n",
       "Baldwin_Alabama_UnitedStates                    {'id': '01003'}   \n",
       "Barbour_Alabama_UnitedStates                    {'id': '01005'}   \n",
       "Bibb_Alabama_UnitedStates                       {'id': '01007'}   \n",
       "Blount_Alabama_UnitedStates                     {'id': '01009'}   \n",
       "...                                                         ...   \n",
       "Unassigned_Wisconsin_UnitedStates                           NaN   \n",
       "Unassigned_Wyoming_UnitedStates                             NaN   \n",
       "Unassigned_Guam_UnitedStates                                NaN   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates              NaN   \n",
       "Unassigned_PuertoRico_UnitedStates                          NaN   \n",
       "\n",
       "                                                                                            id  \\\n",
       "Autauga_Alabama_UnitedStates                                      Autauga_Alabama_UnitedStates   \n",
       "Baldwin_Alabama_UnitedStates                                      Baldwin_Alabama_UnitedStates   \n",
       "Barbour_Alabama_UnitedStates                                      Barbour_Alabama_UnitedStates   \n",
       "Bibb_Alabama_UnitedStates                                            Bibb_Alabama_UnitedStates   \n",
       "Blount_Alabama_UnitedStates                                        Blount_Alabama_UnitedStates   \n",
       "...                                                                                        ...   \n",
       "Unassigned_Wisconsin_UnitedStates                            Unassigned_Wisconsin_UnitedStates   \n",
       "Unassigned_Wyoming_UnitedStates                                Unassigned_Wyoming_UnitedStates   \n",
       "Unassigned_Guam_UnitedStates                                      Unassigned_Guam_UnitedStates   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates  Unassigned_NorthernMarianaIslands_UnitedStates   \n",
       "Unassigned_PuertoRico_UnitedStates                          Unassigned_PuertoRico_UnitedStates   \n",
       "\n",
       "                                                      name    version  \\\n",
       "Autauga_Alabama_UnitedStates                       Autauga  3735560.0   \n",
       "Baldwin_Alabama_UnitedStates                       Baldwin  3801096.0   \n",
       "Barbour_Alabama_UnitedStates                       Barbour  3801096.0   \n",
       "Bibb_Alabama_UnitedStates                             Bibb  3997704.0   \n",
       "Blount_Alabama_UnitedStates                         Blount  3801096.0   \n",
       "...                                                    ...        ...   \n",
       "Unassigned_Wisconsin_UnitedStates               Unassigned  3080195.0   \n",
       "Unassigned_Wyoming_UnitedStates                 Unassigned  3080201.0   \n",
       "Unassigned_Guam_UnitedStates                       Unknown        1.0   \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates     Unknown   458755.0   \n",
       "Unassigned_PuertoRico_UnitedStates                 Unknown        1.0   \n",
       "\n",
       "                                               typeIdent  \n",
       "Autauga_Alabama_UnitedStates                      EP_LOC  \n",
       "Baldwin_Alabama_UnitedStates                      EP_LOC  \n",
       "Barbour_Alabama_UnitedStates                      EP_LOC  \n",
       "Bibb_Alabama_UnitedStates                         EP_LOC  \n",
       "Blount_Alabama_UnitedStates                       EP_LOC  \n",
       "...                                                  ...  \n",
       "Unassigned_Wisconsin_UnitedStates                 EP_LOC  \n",
       "Unassigned_Wyoming_UnitedStates                   EP_LOC  \n",
       "Unassigned_Guam_UnitedStates                      EP_LOC  \n",
       "Unassigned_NorthernMarianaIslands_UnitedStates    EP_LOC  \n",
       "Unassigned_PuertoRico_UnitedStates                EP_LOC  \n",
       "\n",
       "[3249 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_population_data(file_name='./config/counties.json'):\n",
    "    \"\"\" Loads all population data for US counties and stores in a file called counties.json\"\"\"\n",
    "\n",
    "    us_locations = get_us_locations()\n",
    "    keep_going = True\n",
    "    tries = 0\n",
    "    while keep_going:\n",
    "        try:\n",
    "            with open(file_name) as file:\n",
    "                county_data = json.load(file)\n",
    "        except:    \n",
    "            county_data = {}\n",
    "        i = 0\n",
    "        for county in us_locations['County id']:\n",
    "            if county not in county_data.keys():\n",
    "                try:\n",
    "                    data = fetch_one('outbreaklocation',  make_outbreaklocation_body(county))\n",
    "                    county_data[county] = data[0]\n",
    "                    i += 1\n",
    "                    if i % 100 == 0:\n",
    "                        print(f'Saving: {i}')\n",
    "                        with open(file_name, 'w') as file:\n",
    "                            json.dump(county_data, file)\n",
    "                except:\n",
    "                    county_data[county] = None\n",
    "                    print(f'Problem with {county}')\n",
    "                sleep(1)\n",
    "        with open('counties.json', 'w') as file:\n",
    "            json.dump(county_data, file)\n",
    "        if len(county_data) >= len(us_locations) or tries >= 5:\n",
    "            keep_going = False\n",
    "        else:\n",
    "            tries += 1\n",
    "        \n",
    "def get_counties_df(file_name='./config/counties.json'):\n",
    "    with open(file_name) as file:\n",
    "                county_data = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(county_data)\n",
    "    \n",
    "    data = [df[col] for col in df.columns]    \n",
    "    \n",
    "    # pivot\n",
    "    return pd.DataFrame(data,columns=df.index, index=df.columns)\n",
    "    \n",
    "get_counties_df()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6005ae-fdc5-4045-adeb-485bab1e83b9",
   "metadata": {},
   "source": [
    "### Get the County Stats from the Census Bureau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd5e8a6-385e-4116-81ff-ca3b3b5375e8",
   "metadata": {},
   "source": [
    "### New source of county date\n",
    "#### co-est2019-annres.xlsx\n",
    "#### from US Census Bureau at https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1ebb9b-df29-49e6-9bc4-242f1ff7f728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>LND110210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3531905.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>50645.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>594.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>1589.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>884.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>56037</td>\n",
       "      <td>10426.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>56039</td>\n",
       "      <td>3995.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>56041</td>\n",
       "      <td>2081.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>56043</td>\n",
       "      <td>2238.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>56045</td>\n",
       "      <td>2398.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fips   LND110210\n",
       "0         0  3531905.43\n",
       "1      1000    50645.33\n",
       "2      1001      594.44\n",
       "3      1003     1589.78\n",
       "4      1005      884.88\n",
       "...     ...         ...\n",
       "3190  56037    10426.65\n",
       "3191  56039     3995.38\n",
       "3192  56041     2081.26\n",
       "3193  56043     2238.55\n",
       "3194  56045     2398.09\n",
       "\n",
       "[3195 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_county_stats_df(file_name='./config/county_stats.csv'):\n",
    "    \"\"\" Get county land area (LND110210) by FIPS code \"\"\"\n",
    "    return pd.read_csv(path.join('.',file_name))[['fips','LND110210']]\n",
    "\n",
    "get_county_stats_df()\n",
    "\n",
    "# Equivalent data https://www.kaggle.com/benhamner/2016-us-election"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde46608-2f28-4ed9-8545-d3c7c561b0f5",
   "metadata": {},
   "source": [
    "### Functions to Download the Evalmetrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca5e879-c521-4af6-a6fe-bc6033bc3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_file_date(county: str) -> str:\n",
    "    \"\"\" Retrieves the last date through which data was loaded for the specified county\n",
    "    \n",
    "    Args:\n",
    "            county: The county requested\n",
    "            \n",
    "    Returns:\n",
    "            A string representing the last date processed.  If the county has never been processed, a\n",
    "            default date of 2020-01-01 is returned\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    max_date = '2020-01-01'\n",
    "    files = glob(path.join('.', 'data', f'{county}*.psv'))\n",
    "    if not files:\n",
    "        return max_date\n",
    "    for file in files:\n",
    "        match = re.search(r'(\\d\\d\\d\\d-\\d\\d-\\d\\d).psv', file)\n",
    "        if match:\n",
    "            max_date = max(max_date, match.group(1))\n",
    "    return max_date\n",
    "            \n",
    "    \n",
    "def download_evalmetrics_data():\n",
    "    \"\"\" Downloads the evalmetrics data from the last download \n",
    "    through current \"\"\"\n",
    "    \n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get the list of counties\n",
    "    counties_file = path.join('.', 'config', 'counties.json')\n",
    "    with open(counties_file) as file:\n",
    "        counties = json.load(file)\n",
    "\n",
    "    # Iterate through counties saving the time series data\n",
    "    for counter, (county, details) in enumerate(counties.items()):\n",
    "        print('.', end='')\n",
    "        if counter and not counter % 120:\n",
    "            print()\n",
    "\n",
    "        # Skip if missing county details\n",
    "        if not details:\n",
    "            continue\n",
    "\n",
    "        # Get the last date we processed\n",
    "        last_date = get_last_file_date(county)\n",
    "\n",
    "        if last_date == today:\n",
    "            continue\n",
    "            \n",
    "        expressions = [    \"JHU_ConfirmedCases\", \n",
    "                           \"JHU_ConfirmedDeaths\", \n",
    "                           \"JHU_ConfirmedRecoveries\",\n",
    "                           \"NYT_ConfirmedCases\",\n",
    "                           \"NYT_ConfirmedDeaths\",\n",
    "                           \"NYT_AllCausesDeathsWeekly_Deaths_AllCauses\",\n",
    "                           \"NYT_AllCausesDeathsWeekly_Excess_Deaths\",\n",
    "                           \"NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses\",\n",
    "                           \"NYT_AllCausesDeathsMonthly_Deaths_AllCauses\",\n",
    "                           \"NYT_AllCausesDeathsMonthly_Excess_Deaths\",\n",
    "                           \"NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses\",\n",
    "                           # \"CDS_Active\",\n",
    "                           # \"CDS_Cases\",\n",
    "                           # \"CDS_Deaths\",\n",
    "                           # \"CDS_Discharged\",\n",
    "                           # \"CDS_GrowthFactor\",\n",
    "                           # \"CDS_Hospitalized\",\n",
    "                           # \"CDS_Hospitalized_Current\",\n",
    "                           # \"CDS_ICU\",\n",
    "                           # \"CDS_ICU_Current\",\n",
    "                           # \"CDS_Recovered\",\n",
    "                           # \"CDS_Tested\",\n",
    "                           \"TotalPopulation\",\n",
    "                           \"Male_Total_Population\",\n",
    "                           \"Female_Total_Population\",\n",
    "                           \"MaleAndFemale_Under18_Population\",\n",
    "                           \"MaleAndFemale_AtLeast65_Population\",\n",
    "                           \"BLS_LaborForcePopulation\",\n",
    "                           \"BLS_EmployedPopulation\",\n",
    "                           \"BLS_UnemployedPopulation\",\n",
    "                           \"BLS_UnemploymentRate\",\n",
    "                           \"AverageDailyTemperature\",\n",
    "                           \"AverageDewPoint\",\n",
    "                           \"AverageRelativeHumidity\",\n",
    "                           \"AverageSurfaceAirPressure\",\n",
    "                           \"AveragePrecipitation\",\n",
    "                           \"AverageWindSpeed\",\n",
    "                           \"AverageWindDirection\",\n",
    "                           \"AveragePrecipitationTotal\",]\n",
    "                                     \n",
    "        # Get the data for the county from the last date processed\n",
    "        for i in range(math.ceil(len(expressions)//4)): \n",
    "            body = {\"spec\" : {\n",
    "                                \"ids\" : [county],\n",
    "                                \"expressions\": expressions[i*4:(i+1)*4] , \n",
    "                                \"start\" : last_date,\n",
    "                                \"end\" : today,\n",
    "                                \"interval\" : \"DAY\",\n",
    "                            }\n",
    "                    }\n",
    "\n",
    "            try:\n",
    "                df = evalmetrics(\"outbreaklocation\", body)\n",
    "                file_name = path.join('.', 'data', f'{county}-part-{i}-{last_date}-{today}.psv')\n",
    "                df.to_csv(file_name, sep='|')\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {county}: {e}')\n",
    "        \n",
    "            sleep(1)\n",
    "  \n",
    "# download_evalmetrics_data()           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc940ac-316b-48e3-a367-989ecb255c8d",
   "metadata": {},
   "source": [
    "### Load all the downloaded data and produce raw DataFrame (OLD - not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f667dc89-9615-41b2-91ea-b8f290b52395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def append_to_dataframe(files: list) -> pd.DataFrame:\n",
    "#     \"\"\" Appends all files passed as an argument into a single dataframe\n",
    "    \n",
    "#     Args:\n",
    "#         files: list of file names\n",
    "        \n",
    "#     Returns:\n",
    "#         A data frame with all the data from the files populated\n",
    "    \n",
    "#     \"\"\"\n",
    "#     name_pattern = re.compile('([\\w_]+)')\n",
    "#     county_df = None\n",
    "\n",
    "#     for file in files:\n",
    "#         base: str = path.basename(file)\n",
    "#         if base.startswith('Unassigned') or base.startswith('Outof') or base.startswith('.'):\n",
    "#             continue\n",
    "#         try:\n",
    "#             county = name_pattern.match(base).group(1)\n",
    "#             records = []\n",
    "#             with open(file) as fd:\n",
    "#                 reader = csv.reader(fd, delimiter='|')\n",
    "#                 # advance past the header\n",
    "#                 next(iter(reader))\n",
    "#                 records = [[county, row[1], row[2], row[4], row[6]] for row in reader]\n",
    "            \n",
    "#             temp_df = pd.DataFrame(records, columns=['county', 'date', \n",
    "#                                                      'confirmed_cases_running', \n",
    "#                                                      'confirmed_deaths_running', \n",
    "#                                                      'confirmed_recoveries_running'])\n",
    "            \n",
    "#             if float(temp_df.confirmed_deaths_running[-1:].values) < 2:\n",
    "#                 continue\n",
    "            \n",
    "#             # turn running amounts into daily amounts\n",
    "#             temp_df['prev_day_cases'] = ['0.0'] + list(temp_df.confirmed_cases_running[:-1])\n",
    "#             temp_df['confirmed_cases'] = (temp_df.confirmed_cases_running.astype('float') - \n",
    "#                                           temp_df.prev_day_cases.astype('float'))\n",
    "            \n",
    "#             temp_df['prev_day_deaths'] = ['0.0'] + list(temp_df.confirmed_deaths_running[:-1])\n",
    "#             temp_df['confirmed_deaths'] = (temp_df.confirmed_deaths_running.astype('float') - \n",
    "#                                            temp_df.prev_day_deaths.astype('float'))\n",
    "            \n",
    "#             temp_df['prev_day_recoveries'] = ['0.0'] + list(temp_df.confirmed_recoveries_running[:-1])\n",
    "#             temp_df['confirmed_recoveries'] = (temp_df.confirmed_recoveries_running.astype('float') - \n",
    "#                                                temp_df.prev_day_recoveries.astype('float'))\n",
    "            \n",
    "            \n",
    "#             temp_df = temp_df.drop(columns=['confirmed_cases_running', 'prev_day_cases',\n",
    "#                                             'confirmed_deaths_running', 'prev_day_deaths',\n",
    "#                                             'confirmed_recoveries_running', \n",
    "#                                             'prev_day_recoveries',])\n",
    "#             if county_df is None:\n",
    "#                 county_df = temp_df\n",
    "#             else:\n",
    "#                 county_df = pd.concat([county_df, temp_df], ignore_index=True)\n",
    "#         except Exception as e:\n",
    "#             print(f'Failure on file {base} with error {e}')\n",
    "        \n",
    "#     return county_df\n",
    "\n",
    "# def join_evalmetrics_to_county(evalmetrics_df, counties_df, county_stats_df):\n",
    "#     df = evalmetrics_df.merge(counties_df, how='left', left_on='county', right_index=True, sort=True)\n",
    "#     # df.fips = [int(fips['id']) for fips in df.fips]\n",
    "#     fips = []\n",
    "#     for f in df.fips:\n",
    "#         if isinstance(f, dict):\n",
    "#             fips.append(int(f['id']))\n",
    "#         else:\n",
    "#             fips.append(f)\n",
    "#     df.fips = fips\n",
    "#     df = df.merge(county_stats_df, how='left', left_on='fips', right_on='fips')\n",
    "#     df = df.drop(columns=['location', 'id', 'name', 'version', 'typeIdent'])\n",
    "    \n",
    "#     return df.sort_values(by=['county', 'date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ebca6-fafc-4355-866c-b69f1e56d88b",
   "metadata": {},
   "source": [
    "### Save the raw dataframe to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe61bbb-3777-422a-867a-357736fc4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_df(df: pd.DataFrame):\n",
    "    df.to_pickle(path.join('.', 'raw_evalmetrics_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b53bc-46b9-4342-a086-a6b152cf39dc",
   "metadata": {},
   "source": [
    "### Runners\n",
    "#### The following runners can take a significant amount of time to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49274605-7266-4f80-af5a-204554a7aa8e",
   "metadata": {},
   "source": [
    "##### Download Evalmetrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edbd455-c830-4fcf-b06a-43ba85b647d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................Error processing Dallas_Alabama_UnitedStates: ('Connection aborted.', TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))\n",
      ".................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "...............<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Error processing St.Clair_Missouri_UnitedStates: 502 Server Error: Bad Gateway for url: https://api.c3.ai/covid/api/1/outbreaklocation/evalmetrics\n",
      ".........................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      ".................................................................................Error processing Divide_NorthDakota_UnitedStates: ('Connection aborted.', TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03B12B0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03CFBB0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03BDFA0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03AD3D0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03A9CA0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Divide_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03BDB50>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      ".Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03CFF10>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03B1AF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03BAC40>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03A9DF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03A9AF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03A96A0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error processing Dunn_NorthDakota_UnitedStates: HTTPSConnectionPool(host='api.c3.ai', port=443): Max retries exceeded with url: /covid/api/1/outbreaklocation/evalmetrics (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000170A03BAD90>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "......................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........................................................................................................................\n",
      "........"
     ]
    }
   ],
   "source": [
    "download_evalmetrics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66f13e-4055-4cc1-8295-2d83c1013158",
   "metadata": {},
   "source": [
    "#### Convert raw files to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3bdca-5be7-4f9f-9c77-22ebe3a4a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_normalize_df(filename):\n",
    "    df = pd.read_csv(path.join('.', 'data', filename), delimiter='|', index_col=1)\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    columns = {c: '.'.join(c.split('.')[-2:]) for c in df.columns}\n",
    "    df.rename(columns=columns, inplace=True)\n",
    "    return df\n",
    "\n",
    "def merge_county_parts_to_dataframe(filenames):\n",
    "    df = load_and_normalize_df(filenames[0])\n",
    "    for filename in filenames[1:]:\n",
    "        df2 = load_and_normalize_df(filename)\n",
    "        df = df.join(df2)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_county_merged_parts_df(county, df):\n",
    "    df.to_pickle(path.join('.', 'processed_data', 'county_merged_parts', \n",
    "                           f'{county}.pkl'))\n",
    "    \n",
    "\n",
    "def get_counties_from_files():\n",
    "    return list({f.split('-part')[0] for f in os.listdir(path.join('.', 'data'))})\n",
    "\n",
    "\n",
    "def get_dates_for_county(county):\n",
    "    files = glob(f'./data/{county}*' )\n",
    "    dates = {re.findall('\\d\\d\\d\\d-\\d\\d-\\d\\d-\\d\\d\\d\\d-\\d\\d-\\d\\d', f)[0] for f in files}\n",
    "    return list(dates)\n",
    "    \n",
    "def get_county_files_for_date(county, dt):\n",
    "    files = glob(f'./data/{county}-part-*-{dt}.psv')\n",
    "    return [f[f.index(county):]  for f in files]\n",
    "                    \n",
    "def process_county(county, county_population_stats):\n",
    "    df = None\n",
    "    dates = get_dates_for_county(county)\n",
    "    for dt in dates:\n",
    "        files = get_county_files_for_date(county, dt)\n",
    "        if df:\n",
    "            df.append(merge_county_parts_to_dataframe(files))\n",
    "        else:\n",
    "            df = merge_county_parts_to_dataframe(files)\n",
    "    \n",
    "    for k,v in county_population_stats.iteritems():\n",
    "        df[k] = v\n",
    "    save_county_merged_parts_df(county, df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_county_population_stats():\n",
    "    county_population = get_counties_df()  \n",
    "    county_stats = get_county_stats_df()\n",
    "    fips = []\n",
    "    for county, population in county_population.iterrows():\n",
    "        if isinstance(population.fips, dict):\n",
    "            fips.append(int(population.fips['id']))\n",
    "        else:\n",
    "            fips.append(population.fips)\n",
    "    county_population.fips = fips\n",
    "    county_population = county_population.merge(county_stats, how='left', left_on='fips', right_on='fips')\n",
    "    county_population.set_index('id', inplace=True)\n",
    "    county_population = county_population.drop(columns=['location', 'name', 'version', 'typeIdent'])\n",
    "    return county_population\n",
    "\n",
    "    \n",
    "def process_counties():\n",
    "    counties = get_counties_from_files()\n",
    "    county_population_stats = get_county_population_stats()  \n",
    "    \n",
    "    for county in counties:\n",
    "        # print(county)\n",
    "        process_county(county, county_population_stats.loc[county])\n",
    "\n",
    "        \n",
    "# get_county_population_stats()\n",
    "process_counties()        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698691a2-fbc3-4b7a-b77e-70c8dfe35fdd",
   "metadata": {},
   "source": [
    "### Collect Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddedecdd-5beb-4143-aa5c-3f10651ea1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hospitalIcuBeds': 6,\n",
       "  'hospitalStaffedBeds': 55,\n",
       "  'hospitalLicensedBeds': 85,\n",
       "  'latestTotalPopulation': 55869.0,\n",
       "  'populationOfAllChildren': 55869.0,\n",
       "  'latestLaborForce': 25541,\n",
       "  'latestEmployedPopulation': 24953,\n",
       "  'latestUnemployedPopulation': 588,\n",
       "  'latestUnemploymentRate': 2.302180807329392,\n",
       "  'laborForceOfAllChildren': 25541,\n",
       "  'locationType': 'county',\n",
       "  'populationCDS': 55869,\n",
       "  'location': {'value': {'id': 'Autauga_Alabama_UnitedStates'},\n",
       "   'timestamp': '2021-08-04T00:00:00Z'},\n",
       "  'fips': {'id': '01001'},\n",
       "  'id': 'Autauga_Alabama_UnitedStates',\n",
       "  'name': 'Autauga',\n",
       "  'version': 38863297,\n",
       "  'typeIdent': 'EP_LOC'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_outbreaklocation_body(county_id: str) -> dict:\n",
    "    \"\"\" Forms the request body for a count for the outbreak location API \n",
    "    \n",
    "    Args:\n",
    "        count_id: the ID for the County\n",
    "    \n",
    "    Returns:\n",
    "        The request body\n",
    "    \n",
    "    \"\"\"\n",
    "    return {\n",
    "              \"spec\": {\n",
    "                \"filter\": f\"id == '{county_id}'\"\n",
    "              }\n",
    "}\n",
    "\n",
    "fetch_one('outbreaklocation', make_outbreaklocation_body('Autauga_Alabama_UnitedStates'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85199f1d-7727-4bf8-b2dd-39fcd4dc4623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
