{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c4fe28",
   "metadata": {},
   "source": [
    "Libraries and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859eb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, sys, os, re, matplotlib.pyplot as plt, seaborn as sns,time\n",
    "import json, shutil, zipfile, bz2, pickle\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_colwidth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c60b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counties_df(file_name='../covid/config/counties.json'):\n",
    "    with open(file_name) as file:\n",
    "                county_data = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(county_data)\n",
    "    \n",
    "    data = [df[col] for col in df.columns]    \n",
    "    \n",
    "    # pivot\n",
    "    return pd.DataFrame(data,columns=df.index, index=df.columns)\n",
    "    \n",
    "counties = get_counties_df()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41645bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counties['fips'] = counties['fips']['id'].astype(str)\n",
    "\n",
    "a = [x['id'] for x in counties['fips'][~counties['fips'].isnull()] ]\n",
    "counties.loc[counties['fips'].notnull(),'fips'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04b81a",
   "metadata": {},
   "source": [
    "Importing census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbf5968",
   "metadata": {},
   "outputs": [],
   "source": [
    "censusDF = pd.read_csv('./censusData.csv')\n",
    "\n",
    "censusDF['fips'] = censusDF['fips'].astype('str').str.zfill(5)\n",
    "censusDF['state']  = censusDF['state'].astype('str').str.zfill(2)\n",
    "censusDF['county'] = censusDF['county'].astype('str').str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7d201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=[print('###',i,j) for i,j in enumerate(censusDF.columns)]\n",
    "cols=['totalMoved','movedWithinState','movedWithoutState','movedFromAbroad','publicTrans','totalTrans','householdsTotal',\n",
    "      'houseWith65','house2+with65','houseFamily65','houseNonfam65','houseNo65',\n",
    "      'house2+No65','houseFamilyNo65','houseNonfamNo65','householdStructuresTotal','householdIncomeMedian',\n",
    "      'gini','hoursWorkedMean','unitsInStructure','healthInsTotal','healthInsNativeWith',\n",
    "      'healthInsForeignNatWith','healthInsForeignNoncitWith','healthInsForeignNatNo','healthInsForeignNoncitNo','healthInsNativeNo',\n",
    "      'name','state','county','fips'\n",
    "     ]\n",
    "censusDF = pd.DataFrame(censusDF.values, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62692ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = counties.index\n",
    "x = [re.search('.*(?=_UnitedStates)',x).group(0).split('_') for x in a]\n",
    "x,y = zip(*x)\n",
    "counties['coName'] = x\n",
    "counties['stName'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1039f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cenCounty( c ):\n",
    "    toby =  []\n",
    "    for x in c:\n",
    "        try:\n",
    "            toby.append(re.search('.*(?=\\sCounty|\\sCity\\sand\\sBorough|(?<!and)\\sBorough|\\sCensus|\\sMunicipality)',x).group(0))\n",
    "        except:\n",
    "            toby.append(re.search('.*(?=,\\s)',x).group(0))\n",
    "    return toby\n",
    "\n",
    "def cenState( c ):\n",
    "    toby =  []\n",
    "    for x in c:\n",
    "        try:\n",
    "            toby.append(re.search('(?<=,\\s).*$',x).group(0))\n",
    "        except:\n",
    "            print('problem',x)\n",
    "            raise Exception('What the hell???')\n",
    "    return toby\n",
    "\n",
    "def addSpace( df,col ):\n",
    "    vals = df[col].values\n",
    "    return [re.sub('(?<=[a-z]|\\.)(?=[A-Z])',' ',x) for x in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9b7440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>coName</th>\n",
       "      <th>stName</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fayette County, Illinois</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logan County, Illinois</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saline County, Illinois</td>\n",
       "      <td>Saline</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lake County, Illinois</td>\n",
       "      <td>Lake</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Massac County, Illinois</td>\n",
       "      <td>Massac</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>17127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>Crockett County, Tennessee</td>\n",
       "      <td>Crockett</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>47033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>Lake County, Tennessee</td>\n",
       "      <td>Lake</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>47095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>Knox County, Tennessee</td>\n",
       "      <td>Knox</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>47093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>Benton County, Washington</td>\n",
       "      <td>Benton</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>Clark County, Washington</td>\n",
       "      <td>Clark</td>\n",
       "      <td>Washington</td>\n",
       "      <td>53011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name    coName      stName   fips\n",
       "0       Fayette County, Illinois   Fayette    Illinois  17051\n",
       "1         Logan County, Illinois     Logan    Illinois  17107\n",
       "2        Saline County, Illinois    Saline    Illinois  17165\n",
       "3          Lake County, Illinois      Lake    Illinois  17097\n",
       "4        Massac County, Illinois    Massac    Illinois  17127\n",
       "...                          ...       ...         ...    ...\n",
       "3215  Crockett County, Tennessee  Crockett   Tennessee  47033\n",
       "3216      Lake County, Tennessee      Lake   Tennessee  47095\n",
       "3217      Knox County, Tennessee      Knox   Tennessee  47093\n",
       "3218   Benton County, Washington    Benton  Washington  53005\n",
       "3219    Clark County, Washington     Clark  Washington  53011\n",
       "\n",
       "[3220 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  censusDF.name.values\n",
    "x = cenCounty(a)\n",
    "censusDF['coName'] =  x\n",
    "y = cenState(a)\n",
    "censusDF['stName'] = y\n",
    "censusDF[['name','coName','stName','fips']]\n",
    "\n",
    "# [counties[x].index for x in counties.index if re.match('Unassigned_',x)]\n",
    "# biggy = []\n",
    "# for x in counties.index:\n",
    "#     if re.match('Unassigned_|Outof',x):\n",
    "#         biggy.append(x)\n",
    "# counties.drop(biggy,inplace=True)\n",
    "# counties.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f333b2",
   "metadata": {},
   "source": [
    "Importing covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386525e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../covid/processed_data/county_merged_parts/'\n",
    "listFiles = []\n",
    "for r, d, files in os.walk(path):\n",
    "    for file in files:\n",
    "        listFiles.append(file)\n",
    "\n",
    "testDF = pd.DataFrame()\n",
    "for i,file in enumerate(listFiles):\n",
    "    inDF = pd.read_pickle(f'{path}{file}')\n",
    "    inDF['bigName'] = re.search('.*(?=.pkl)',file).group(0)\n",
    "    inDF.reset_index(level=0,inplace=True)\n",
    "    testDF = pd.concat([testDF,inDF],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8b7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounty( c ):\n",
    "    toby =  []\n",
    "    for x in c:\n",
    "        try:\n",
    "            toby.append(re.search('^.*(?=_(?!United))',x).group(0))\n",
    "        except:\n",
    "            print('problem',x)\n",
    "    return toby\n",
    "\n",
    "def getState( c ):\n",
    "    toby =  []\n",
    "    for x in c:\n",
    "        try:\n",
    "            toby.append(re.search('(?<=_).*(?=.UnitedStates)',x).group(0))\n",
    "        except:\n",
    "            print('problem',x)\n",
    "    return toby    \n",
    "\n",
    "def addSpace( df,col ):\n",
    "    vals = df[col].values\n",
    "    return [re.sub('(?<=[a-z]|\\.)(?=[A-Z])',' ',x) for x in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7740012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigName</th>\n",
       "      <th>coName</th>\n",
       "      <th>stName</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbeville_SouthCarolina_UnitedStates</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbeville_SouthCarolina_UnitedStates</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbeville_SouthCarolina_UnitedStates</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbeville_SouthCarolina_UnitedStates</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbeville_SouthCarolina_UnitedStates</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122225</th>\n",
       "      <td>Ziebach_SouthDakota_UnitedStates</td>\n",
       "      <td>Ziebach</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122226</th>\n",
       "      <td>Ziebach_SouthDakota_UnitedStates</td>\n",
       "      <td>Ziebach</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122227</th>\n",
       "      <td>Ziebach_SouthDakota_UnitedStates</td>\n",
       "      <td>Ziebach</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122228</th>\n",
       "      <td>Ziebach_SouthDakota_UnitedStates</td>\n",
       "      <td>Ziebach</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122229</th>\n",
       "      <td>Ziebach_SouthDakota_UnitedStates</td>\n",
       "      <td>Ziebach</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>46137.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2122230 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bigName     coName          stName  \\\n",
       "0        Abbeville_SouthCarolina_UnitedStates  Abbeville  South Carolina   \n",
       "1        Abbeville_SouthCarolina_UnitedStates  Abbeville  South Carolina   \n",
       "2        Abbeville_SouthCarolina_UnitedStates  Abbeville  South Carolina   \n",
       "3        Abbeville_SouthCarolina_UnitedStates  Abbeville  South Carolina   \n",
       "4        Abbeville_SouthCarolina_UnitedStates  Abbeville  South Carolina   \n",
       "...                                       ...        ...             ...   \n",
       "2122225      Ziebach_SouthDakota_UnitedStates    Ziebach    South Dakota   \n",
       "2122226      Ziebach_SouthDakota_UnitedStates    Ziebach    South Dakota   \n",
       "2122227      Ziebach_SouthDakota_UnitedStates    Ziebach    South Dakota   \n",
       "2122228      Ziebach_SouthDakota_UnitedStates    Ziebach    South Dakota   \n",
       "2122229      Ziebach_SouthDakota_UnitedStates    Ziebach    South Dakota   \n",
       "\n",
       "            fips  \n",
       "0        45001.0  \n",
       "1        45001.0  \n",
       "2        45001.0  \n",
       "3        45001.0  \n",
       "4        45001.0  \n",
       "...          ...  \n",
       "2122225  46137.0  \n",
       "2122226  46137.0  \n",
       "2122227  46137.0  \n",
       "2122228  46137.0  \n",
       "2122229  46137.0  \n",
       "\n",
       "[2122230 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  testDF.bigName.values\n",
    "x = getCounty(a)\n",
    "testDF['coName'] =  x\n",
    "testDF['coName'] =  addSpace(testDF,'coName')\n",
    "y = getState(a)\n",
    "y\n",
    "testDF['stName'] = y\n",
    "testDF['stName'] = addSpace(testDF,'stName')\n",
    "testDF[['bigName','coName','stName','fips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c317218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF['intfips'] = testDF['fips'].fillna(0).astype(int)\n",
    "testDF['intfips']= testDF['intfips'].round()\n",
    "testDF['strfips'] = testDF['intfips'].astype(str)\n",
    "testDF['fips'] =testDF['strfips']\n",
    "testDF['fips'].where(testDF['fips']!='0',inplace=True)\n",
    "testDF.drop(columns=['intfips','strfips'],inplace=True)\n",
    "testDF['fips'] = testDF['fips'].str.zfill(5)\n",
    "testDF['fips'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b710aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF['dates'] = pd.to_datetime(testDF['dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc5b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dukesand Nantucket', 'Falls Church', 'Kansas City',\n",
       "       'Kodiak Island', 'Lakeand Peninsula', 'Lakeofthe Woods',\n",
       "       'La Moure', 'Martinsville', 'Mc Cone', 'Mc Mullen',\n",
       "       'New York City', 'Norton', 'Outof AK', 'Outof AL', 'Outof AR',\n",
       "       'Outof AZ', 'Outof CA', 'Outof CO', 'Outof CT', 'Outof DC',\n",
       "       'Outof DE', 'Outof FL', 'Outof GA', 'Outof HI', 'Outof IA',\n",
       "       'Outof ID', 'Outof IL', 'Outof IN', 'Outof KS', 'Outof KY',\n",
       "       'Outof LA', 'Outof MA', 'Outof MD', 'Outof ME', 'Outof MI',\n",
       "       'Outof MN', 'Outof MO', 'Outof MS', 'Outof MT', 'Outof NC',\n",
       "       'Outof ND', 'Outof NE', 'Outof NH', 'Outof NJ', 'Outof NM',\n",
       "       'Outof NV', 'Outof NY', 'Outof OH', 'Outof OK', 'Outof OR',\n",
       "       'Outof PA', 'Outof RI', 'Outof SC', 'Outof SD', 'Outof TN',\n",
       "       'Outof TX', 'Outof UT', 'Outof VA', 'Outof VT', 'Outof WA',\n",
       "       'Outof WI', 'Outof WV', 'Outof WY', 'Princeof Wales-Hyder',\n",
       "       'St. Bernard', 'St. Charles', 'St. Helena', 'St. James',\n",
       "       'St. Johnthe Baptist', 'St. Landry', 'St. Louis City',\n",
       "       'St. Martin', 'St. Mary', 'St. Tammany', 'Unassigned'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = testDF['fips'].isnull()\n",
    "indices = testDF[mask].index\n",
    "noFips = testDF.loc[indices,['coName','stName']]\n",
    "noFips['index'] = noFips.index\n",
    "test = noFips.merge(censusDF[['coName','stName','fips']],left_on=['coName','stName'],right_on=['coName','stName'],how='left')\n",
    "test.set_index(test['index'],inplace=True)\n",
    "test['coName'][test['fips'].isnull()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9fe1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.loc[testDF['fips'].isnull(),'fips'] = test['fips']\n",
    "testDF.dropna(axis=0,subset=['fips'],inplace=True)\n",
    "# testDF[testDF['coName']=='St. Clair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b93288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2038518, 66)\n",
      "(2038518, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>JHU_ConfirmedCases.data</th>\n",
       "      <th>JHU_ConfirmedCases.missing</th>\n",
       "      <th>NYT_ConfirmedCases.data</th>\n",
       "      <th>NYT_ConfirmedCases.missing</th>\n",
       "      <th>JHU_ConfirmedDeaths.data</th>\n",
       "      <th>JHU_ConfirmedDeaths.missing</th>\n",
       "      <th>JHU_ConfirmedRecoveries.data</th>\n",
       "      <th>JHU_ConfirmedRecoveries.missing</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.data</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.missing</th>\n",
       "      <th>NYT_ConfirmedDeaths.data</th>\n",
       "      <th>NYT_ConfirmedDeaths.missing</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Excess_Deaths.data</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Excess_Deaths.missing</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Deaths_AllCauses.data</th>\n",
       "      <th>NYT_AllCausesDeathsWeekly_Deaths_AllCauses.missing</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Deaths_AllCauses.data</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Deaths_AllCauses.missing</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Excess_Deaths.data</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Excess_Deaths.missing</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.data</th>\n",
       "      <th>NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.missing</th>\n",
       "      <th>TotalPopulation.data</th>\n",
       "      <th>TotalPopulation.missing</th>\n",
       "      <th>MaleAndFemale_AtLeast65_Population.data</th>\n",
       "      <th>MaleAndFemale_AtLeast65_Population.missing</th>\n",
       "      <th>Male_Total_Population.data</th>\n",
       "      <th>Male_Total_Population.missing</th>\n",
       "      <th>Female_Total_Population.data</th>\n",
       "      <th>Female_Total_Population.missing</th>\n",
       "      <th>MaleAndFemale_Under18_Population.data</th>\n",
       "      <th>MaleAndFemale_Under18_Population.missing</th>\n",
       "      <th>BLS_EmployedPopulation.data</th>\n",
       "      <th>BLS_EmployedPopulation.missing</th>\n",
       "      <th>BLS_UnemployedPopulation.data</th>\n",
       "      <th>BLS_UnemployedPopulation.missing</th>\n",
       "      <th>BLS_UnemploymentRate.data</th>\n",
       "      <th>BLS_UnemploymentRate.missing</th>\n",
       "      <th>BLS_LaborForcePopulation.data</th>\n",
       "      <th>BLS_LaborForcePopulation.missing</th>\n",
       "      <th>AverageDailyTemperature.data</th>\n",
       "      <th>AverageDailyTemperature.missing</th>\n",
       "      <th>AverageDewPoint.data</th>\n",
       "      <th>AverageDewPoint.missing</th>\n",
       "      <th>AverageRelativeHumidity.data</th>\n",
       "      <th>AverageRelativeHumidity.missing</th>\n",
       "      <th>AverageSurfaceAirPressure.data</th>\n",
       "      <th>AverageSurfaceAirPressure.missing</th>\n",
       "      <th>AveragePrecipitationTotal.data</th>\n",
       "      <th>AveragePrecipitationTotal.missing</th>\n",
       "      <th>AveragePrecipitation.data</th>\n",
       "      <th>AveragePrecipitation.missing</th>\n",
       "      <th>AverageWindDirection.data</th>\n",
       "      <th>AverageWindDirection.missing</th>\n",
       "      <th>AverageWindSpeed.data</th>\n",
       "      <th>AverageWindSpeed.missing</th>\n",
       "      <th>hospitalIcuBeds</th>\n",
       "      <th>hospitalStaffedBeds</th>\n",
       "      <th>hospitalLicensedBeds</th>\n",
       "      <th>latestTotalPopulation</th>\n",
       "      <th>fips</th>\n",
       "      <th>LND110210</th>\n",
       "      <th>bigName</th>\n",
       "      <th>coName</th>\n",
       "      <th>stName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dates, JHU_ConfirmedCases.data, JHU_ConfirmedCases.missing, NYT_ConfirmedCases.data, NYT_ConfirmedCases.missing, JHU_ConfirmedDeaths.data, JHU_ConfirmedDeaths.missing, JHU_ConfirmedRecoveries.data, JHU_ConfirmedRecoveries.missing, NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.data, NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.missing, NYT_ConfirmedDeaths.data, NYT_ConfirmedDeaths.missing, NYT_AllCausesDeathsWeekly_Excess_Deaths.data, NYT_AllCausesDeathsWeekly_Excess_Deaths.missing, NYT_AllCausesDeathsWeekly_Deaths_AllCauses.data, NYT_AllCausesDeathsWeekly_Deaths_AllCauses.missing, NYT_AllCausesDeathsMonthly_Deaths_AllCauses.data, NYT_AllCausesDeathsMonthly_Deaths_AllCauses.missing, NYT_AllCausesDeathsMonthly_Excess_Deaths.data, NYT_AllCausesDeathsMonthly_Excess_Deaths.missing, NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.data, NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.missing, TotalPopulation.data, TotalPopulation.missing, MaleAndFemale_AtLeast65_Population.data, MaleAndFemale_AtLeast65_Population.missing, Male_Total_Population.data, Male_Total_Population.missing, Female_Total_Population.data, Female_Total_Population.missing, MaleAndFemale_Under18_Population.data, MaleAndFemale_Under18_Population.missing, BLS_EmployedPopulation.data, BLS_EmployedPopulation.missing, BLS_UnemployedPopulation.data, BLS_UnemployedPopulation.missing, BLS_UnemploymentRate.data, BLS_UnemploymentRate.missing, BLS_LaborForcePopulation.data, BLS_LaborForcePopulation.missing, AverageDailyTemperature.data, AverageDailyTemperature.missing, AverageDewPoint.data, AverageDewPoint.missing, AverageRelativeHumidity.data, AverageRelativeHumidity.missing, AverageSurfaceAirPressure.data, AverageSurfaceAirPressure.missing, AveragePrecipitationTotal.data, AveragePrecipitationTotal.missing, AveragePrecipitation.data, AveragePrecipitation.missing, AverageWindDirection.data, AverageWindDirection.missing, AverageWindSpeed.data, AverageWindSpeed.missing, hospitalIcuBeds, hospitalStaffedBeds, hospitalLicensedBeds, latestTotalPopulation, fips, LND110210, bigName, coName, stName]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testDF.shape)\n",
    "mask = testDF.isnull().any(axis=0)\n",
    "noNullDF = testDF.loc[:,~mask]\n",
    "print(noNullDF.shape)\n",
    "testDF[testDF['fips'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8da9bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'../covid/processed_data/county_merged_parts/'\n",
    "# listFiles = []\n",
    "# for r, d, files in os.walk(path):\n",
    "#     for file in files:\n",
    "#         listFiles.append(file)\n",
    "\n",
    "# testDF = pd.DataFrame()\n",
    "# for i,file in enumerate(listFiles):\n",
    "#     inDF = pd.read_pickle(f'{path}{file}')\n",
    "#     inDF.reset_index(level=0,inplace=True)\n",
    "#     testDF = pd.concat([testDF,inDF],ignore_index=True)\n",
    "# # test = f'{path}{listFiles[0]}'\n",
    "# # testDF= pd.read_pickle(test)\n",
    "\n",
    "# # mask = testDF['fips'].isnull()\n",
    "# testDF.dropna(subset=['fips'], inplace=True)\n",
    "\n",
    "# testDF['fips']=testDF['fips'].astype(int).astype(str)\n",
    "\n",
    "# testDF['fips'] = testDF['fips'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f64970",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.sort_values(['fips','dates'])['fips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c703eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = testDF.groupby(['fips']).rolling(on='dates',window=7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0184a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5c51b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.set_index('level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9edfaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt[['LND110210','bigName','coName','stName','ddates']]  = testDF[['LND110210','bigName','coName','stName','dates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1baaf166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportPbz2( outfile, infile ):\n",
    "    start = time.time()\n",
    "    with bz2.BZ2File(outfile+'.pbz2','wb') as file:\n",
    "        pickle.dump(infile,file)\n",
    "    print(time.time()-start)\n",
    "    \n",
    "def importPbz2( file ):\n",
    "    start = time.time()\n",
    "    data = bz2.BZ2File(file,'rb')\n",
    "    return pd.read_pickle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9293fd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.7743284702301\n"
     ]
    }
   ],
   "source": [
    "exportPbz2('covid',tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f46190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = importPbz2('covid.pbz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b87169",
   "metadata": {},
   "source": [
    "Joining census and covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484997a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = tt.join(censusDF.set_index('fips'),on='fips',how='left',lsuffix='covid',rsuffix='census')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab2ca7",
   "metadata": {},
   "source": [
    "Exported this DF for future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6b43046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.52572059631348\n"
     ]
    }
   ],
   "source": [
    "exportPbz2('covidCensus',newDF)\n",
    "\n",
    "# newDF.to_csv('covidCensus.gz',index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2ebab",
   "metadata": {},
   "source": [
    "Imported back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce2ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anotherDF = pd.read_csv('covidCensus.gz')\n",
    "# anotherDF['fips'] = anotherDF['fips'].astype(str)\n",
    "# anotherDF['dates']=pd.to_datetime(anotherDF['dates'])\n",
    "# anotherDF = newDF.copy()\n",
    "anotherDF = importPbz2('covidCensus.pbz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12442f5",
   "metadata": {},
   "source": [
    "Import air quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c50c8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead\n",
      "lead\n",
      "lead\n",
      "no2\n",
      "no2\n",
      "no2\n",
      "ozone\n",
      "ozone\n",
      "ozone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richs\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm25\n",
      "pm25\n",
      "pm25\n"
     ]
    }
   ],
   "source": [
    "path = r'../air_quality/'\n",
    "dirs = next(os.walk(path))[1]\n",
    "airDF = pd.DataFrame()\n",
    "cols = []\n",
    "for dir in dirs:\n",
    "    files = next(os.walk(f'{path}{dir}/unzipped/'))[2]\n",
    "    for m,file in enumerate(files):\n",
    "        inDF = pd.read_csv(f'{path}{dir}/unzipped/{file}')\n",
    "        cols.append(inDF.columns.values)\n",
    "        inDF['Date of Last Change'] = pd.to_datetime(inDF['Date of Last Change'])\n",
    "        inDF['Date Local']= pd.to_datetime(inDF['Date Local'])\n",
    "        inDF['fips'] = inDF['fips'].astype(str).str.zfill(5)\n",
    "        prefix = re.search('(?<=daily_)[^_]*(?=_)', f'{file}').group(0)\n",
    "        print(prefix)\n",
    "        inDF['pollutant'] = prefix\n",
    "#         inDF = inDF.add_prefix(prefix+'_')\n",
    "        airDF =pd.concat([airDF,inDF],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb361f",
   "metadata": {},
   "source": [
    "Getting all unique fips from air quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f51281",
   "metadata": {},
   "outputs": [],
   "source": [
    "airFips = airDF['fips'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d452a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "airDF.sort_values(by=['pollutant','Date Local','fips'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6d617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2wop = airDF[airDF['pollutant']=='no2'].copy()\n",
    "leadwop = airDF[airDF['pollutant']=='lead'].copy()\n",
    "pm25wop = airDF[airDF['pollutant']=='pm25'].copy()\n",
    "ozonewop = airDF[airDF['pollutant']=='ozone'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e247d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC',\n",
       "       'Latitude', 'Longitude', 'Datum', 'Parameter Name', 'Sample Duration',\n",
       "       'Pollutant Standard', 'Date Local', 'Units of Measure', 'Event Type',\n",
       "       'Observation Count', 'Observation Percent', 'Arithmetic Mean',\n",
       "       '1st Max Value', '1st Max Hour', 'AQI', 'Method Code', 'Method Name',\n",
       "       'Local Site Name', 'Address', 'State Name', 'County Name', 'City Name',\n",
       "       'CBSA Name', 'Date of Last Change', 'fips', 'pollutant', 'Mean ugm3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b37b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nairDF = airDF.groupby(['pollutant','Date Local','fips']).agg({'Arithmetic Mean':'mean','Mean ugm3':'mean'})\n",
    "\n",
    "nairDF.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ba37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "polDF = nairDF.merge(airDF, left_on=['Date Local','fips','pollutant'], right_on=['Date Local','fips','pollutant'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c29cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in airDF['pollutant'].unique():\n",
    "    wob = airDF[['Date Local','Arithmetic Mean']][airDF['pollutant']==a].rolling(window=7,on='Date Local').mean()\n",
    "    airDF.loc[airDF['pollutant']==a,'rollMeanMean'] = wob['Arithmetic Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ecf16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wob = airDF[['Date Local','Mean ugm3']][airDF['pollutant']=='no2'].rolling(window=7,on='Date Local').mean()\n",
    "airDF.loc[airDF['pollutant']=='no2','rollMeanUgm3'] = wob['Mean ugm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2b2857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23545          NaN\n",
       "23890          NaN\n",
       "24240          NaN\n",
       "24464          NaN\n",
       "24829          NaN\n",
       "25189          NaN\n",
       "25554    17.987273\n",
       "25919    21.965007\n",
       "26227    22.384309\n",
       "26592    18.007714\n",
       "26938    16.821524\n",
       "27302    14.689738\n",
       "27658    14.942643\n",
       "28023    14.452889\n",
       "28386    11.749952\n",
       "28750    13.145258\n",
       "29112    15.475018\n",
       "29474    18.264560\n",
       "29838    20.291058\n",
       "30198    21.407478\n",
       "Name: rollMeanUgm3, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airDF.loc[airDF['pollutant']=='no2','rollMeanUgm3'].head(20)\n",
    "# airDF['rollMeanUgm3'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66d3d349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.17634201049805\n"
     ]
    }
   ],
   "source": [
    "exportPbz2('pollution',airDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86965e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "airDF = importPbz2('pollution.pbz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2309d9",
   "metadata": {},
   "source": [
    "Merge air and covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adceab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# tt['ddates']=pd.to_datetime(tt['dates'])\n",
    "airDF['ddates']=pd.to_datetime(airDF['Date Local'])\n",
    "# print(tt['ddates'].dtype)\n",
    "print(airDF['ddates'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8822b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919\n"
     ]
    }
   ],
   "source": [
    "airFips = airDF['fips'].unique()\n",
    "print(airFips.size)\n",
    "# print(tt['fips'].unique().size)\n",
    "# tt['fips'] = tt['fips'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42a2da08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anotherDF['ddates'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d080491",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = anotherDF['fips'].isin(airFips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a364f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = anotherDF.loc[mask,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bad79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586638, 99)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt[ttt['dates']==ttt['ddates']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55dcb630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt['ddates'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deabf2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296      2019-01-01\n",
       "6247      2019-01-01\n",
       "6840      2019-01-01\n",
       "7319      2019-01-01\n",
       "7860      2019-01-01\n",
       "             ...    \n",
       "4565681   2021-04-28\n",
       "4565700   2021-04-28\n",
       "4565719   2021-04-28\n",
       "4565580   2021-04-29\n",
       "4565581   2021-04-30\n",
       "Name: ddates, Length: 4584338, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airDF['ddates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e640487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = ttt.merge(airDF,left_on=['fips','ddates'],right_on=['fips','ddates'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7402ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF['density']=newDF['latestTotalPopulation']/newDF['LND110210']\n",
    "z = newDF[newDF['dates'].isnull()].index\n",
    "newDF.loc[z,'dates'] = newDF.loc[z,'ddates']\n",
    "newDF['dates'] = pd.to_datetime(newDF['dates'])\n",
    "newDF['caseRate'] = newDF['JHU_ConfirmedCases.data']/newDF['latestTotalPopulation']\n",
    "newDF['deathRate'] = newDF['JHU_ConfirmedDeaths.data']/newDF['latestTotalPopulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e1f6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fips\n",
      "dates\n",
      "AverageDailyTemperature.data\n",
      "AverageDailyTemperature.missing\n",
      "AverageDewPoint.data\n",
      "AverageDewPoint.missing\n",
      "AveragePrecipitation.data\n",
      "AveragePrecipitation.missing\n",
      "AveragePrecipitationTotal.data\n",
      "AveragePrecipitationTotal.missing\n",
      "AverageRelativeHumidity.data\n",
      "AverageRelativeHumidity.missing\n",
      "AverageSurfaceAirPressure.data\n",
      "AverageSurfaceAirPressure.missing\n",
      "AverageWindDirection.data\n",
      "AverageWindDirection.missing\n",
      "AverageWindSpeed.data\n",
      "AverageWindSpeed.missing\n",
      "BLS_EmployedPopulation.data\n",
      "BLS_EmployedPopulation.missing\n",
      "BLS_LaborForcePopulation.data\n",
      "BLS_LaborForcePopulation.missing\n",
      "BLS_UnemployedPopulation.data\n",
      "BLS_UnemployedPopulation.missing\n",
      "BLS_UnemploymentRate.data\n",
      "BLS_UnemploymentRate.missing\n",
      "Female_Total_Population.data\n",
      "Female_Total_Population.missing\n",
      "JHU_ConfirmedCases.data\n",
      "JHU_ConfirmedCases.missing\n",
      "JHU_ConfirmedDeaths.data\n",
      "JHU_ConfirmedDeaths.missing\n",
      "JHU_ConfirmedRecoveries.data\n",
      "JHU_ConfirmedRecoveries.missing\n",
      "LND110210\n",
      "MaleAndFemale_AtLeast65_Population.data\n",
      "MaleAndFemale_AtLeast65_Population.missing\n",
      "MaleAndFemale_Under18_Population.data\n",
      "MaleAndFemale_Under18_Population.missing\n",
      "Male_Total_Population.data\n",
      "Male_Total_Population.missing\n",
      "NYT_AllCausesDeathsMonthly_Deaths_AllCauses.data\n",
      "NYT_AllCausesDeathsMonthly_Deaths_AllCauses.missing\n",
      "NYT_AllCausesDeathsMonthly_Excess_Deaths.data\n",
      "NYT_AllCausesDeathsMonthly_Excess_Deaths.missing\n",
      "NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.data\n",
      "NYT_AllCausesDeathsMonthly_Expected_Deaths_AllCauses.missing\n",
      "NYT_AllCausesDeathsWeekly_Deaths_AllCauses.data\n",
      "NYT_AllCausesDeathsWeekly_Deaths_AllCauses.missing\n",
      "NYT_AllCausesDeathsWeekly_Excess_Deaths.data\n",
      "NYT_AllCausesDeathsWeekly_Excess_Deaths.missing\n",
      "NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.data\n",
      "NYT_AllCausesDeathsWeekly_Expected_Deaths_AllCauses.missing\n",
      "NYT_ConfirmedCases.data\n",
      "NYT_ConfirmedCases.missing\n",
      "NYT_ConfirmedDeaths.data\n",
      "NYT_ConfirmedDeaths.missing\n",
      "TotalPopulation.data\n",
      "TotalPopulation.missing\n",
      "hospitalIcuBeds\n",
      "hospitalLicensedBeds\n",
      "hospitalStaffedBeds\n",
      "latestTotalPopulation\n",
      "bigName\n",
      "coNamecovid\n",
      "stNamecovid\n",
      "ddates\n",
      "totalMoved\n",
      "movedWithinState\n",
      "movedWithoutState\n",
      "movedFromAbroad\n",
      "publicTrans\n",
      "totalTrans\n",
      "householdsTotal\n",
      "houseWith65\n",
      "house2+with65\n",
      "houseFamily65\n",
      "houseNonfam65\n",
      "houseNo65\n",
      "house2+No65\n",
      "houseFamilyNo65\n",
      "houseNonfamNo65\n",
      "householdStructuresTotal\n",
      "householdIncomeMedian\n",
      "gini\n",
      "hoursWorkedMean\n",
      "unitsInStructure\n",
      "healthInsTotal\n",
      "healthInsNativeWith\n",
      "healthInsForeignNatWith\n",
      "healthInsForeignNoncitWith\n",
      "healthInsForeignNatNo\n",
      "healthInsForeignNoncitNo\n",
      "healthInsNativeNo\n",
      "name\n",
      "state\n",
      "county\n",
      "coNamecensus\n",
      "stNamecensus\n",
      "State Code\n",
      "County Code\n",
      "Site Num\n",
      "Parameter Code\n",
      "POC\n",
      "Latitude\n",
      "Longitude\n",
      "Datum\n",
      "Parameter Name\n",
      "Sample Duration\n",
      "Pollutant Standard\n",
      "Date Local\n",
      "Units of Measure\n",
      "Event Type\n",
      "Observation Count\n",
      "Observation Percent\n",
      "Arithmetic Mean\n",
      "1st Max Value\n",
      "1st Max Hour\n",
      "AQI\n",
      "Method Code\n",
      "Method Name\n",
      "Local Site Name\n",
      "Address\n",
      "State Name\n",
      "County Name\n",
      "City Name\n",
      "CBSA Name\n",
      "Date of Last Change\n",
      "pollutant\n",
      "Mean ugm3\n",
      "rollMeanMean\n",
      "rollMeanUgm3\n",
      "density\n",
      "caseRate\n",
      "deathRate\n"
     ]
    }
   ],
   "source": [
    "_=[print(x) for x in newDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6aed6b",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f04cb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658.7257816791534\n"
     ]
    }
   ],
   "source": [
    "exportPbz2('covidPollutionCensus',newDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d36130",
   "metadata": {},
   "outputs": [],
   "source": [
    "anotherDF.to_csv('covidCensus.bz2',index=False,compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073f61a",
   "metadata": {},
   "source": [
    "##### Below here is historic junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4157026",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_mean= newDF.groupby(['dates','fips']).agg({'rollMeanMean':'mean', 'rollMeanUgm3':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23292aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rollMeanMean</th>\n",
       "      <th>rollMeanUgm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th>fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019-01-01</th>\n",
       "      <th>01049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02068</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02090</th>\n",
       "      <td>271.019048</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-10-15</th>\n",
       "      <th>56035</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856395 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rollMeanMean  rollMeanUgm3\n",
       "dates      fips                             \n",
       "2019-01-01 01049           NaN           NaN\n",
       "           01073           NaN           NaN\n",
       "           02068           NaN           NaN\n",
       "           02090    271.019048           NaN\n",
       "           04003           NaN           NaN\n",
       "...                        ...           ...\n",
       "2021-10-15 56035           NaN           NaN\n",
       "           56037           NaN           NaN\n",
       "           56039           NaN           NaN\n",
       "           56041           NaN           NaN\n",
       "           56045           NaN           NaN\n",
       "\n",
       "[856395 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79692b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2wop = newDF[newDF['pollutant']=='no2'].copy()\n",
    "leadwop = newDF[newDF['pollutant']=='lead'].copy()\n",
    "pm25wop = newDF[newDF['pollutant']=='pm25'].copy()\n",
    "ozonewop = newDF[newDF['pollutant']=='ozone'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b44637ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rollMeanMean</th>\n",
       "      <th>rollMeanUgm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th>fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019-01-01</th>\n",
       "      <th>01073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02090</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04013</th>\n",
       "      <td>11.052587</td>\n",
       "      <td>20.778863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04019</th>\n",
       "      <td>9.263095</td>\n",
       "      <td>17.414619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05035</th>\n",
       "      <td>7.813691</td>\n",
       "      <td>14.689738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-04-30</th>\n",
       "      <th>19153</th>\n",
       "      <td>5.772294</td>\n",
       "      <td>10.851914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>5.320346</td>\n",
       "      <td>10.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23005</th>\n",
       "      <td>5.629077</td>\n",
       "      <td>10.582664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40109</th>\n",
       "      <td>6.615873</td>\n",
       "      <td>12.437842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40143</th>\n",
       "      <td>7.372421</td>\n",
       "      <td>13.860151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rollMeanMean  rollMeanUgm3\n",
       "dates      fips                             \n",
       "2019-01-01 01073           NaN           NaN\n",
       "           02090           NaN           NaN\n",
       "           04013     11.052587     20.778863\n",
       "           04019      9.263095     17.414619\n",
       "           05035      7.813691     14.689738\n",
       "...                        ...           ...\n",
       "2021-04-30 19153      5.772294     10.851914\n",
       "           19177      5.320346     10.002251\n",
       "           23005      5.629077     10.582664\n",
       "           40109      6.615873     12.437842\n",
       "           40143      7.372421     13.860151\n",
       "\n",
       "[189064 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ea35a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>rollMeanMean</th>\n",
       "      <th>rollMeanUgm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>01073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>02090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>04013</td>\n",
       "      <td>11.052587</td>\n",
       "      <td>20.778863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>04019</td>\n",
       "      <td>9.263095</td>\n",
       "      <td>17.414619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>05035</td>\n",
       "      <td>7.813691</td>\n",
       "      <td>14.689738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>19153</td>\n",
       "      <td>5.772294</td>\n",
       "      <td>10.851914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>19177</td>\n",
       "      <td>5.320346</td>\n",
       "      <td>10.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>23005</td>\n",
       "      <td>5.629077</td>\n",
       "      <td>10.582664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>40109</td>\n",
       "      <td>6.615873</td>\n",
       "      <td>12.437842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>40143</td>\n",
       "      <td>7.372421</td>\n",
       "      <td>13.860151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fips  rollMeanMean  rollMeanUgm3\n",
       "dates                                        \n",
       "2019-01-01  01073           NaN           NaN\n",
       "2019-01-01  02090           NaN           NaN\n",
       "2019-01-01  04013     11.052587     20.778863\n",
       "2019-01-01  04019      9.263095     17.414619\n",
       "2019-01-01  05035      7.813691     14.689738\n",
       "...           ...           ...           ...\n",
       "2021-04-30  19153      5.772294     10.851914\n",
       "2021-04-30  19177      5.320346     10.002251\n",
       "2021-04-30  23005      5.629077     10.582664\n",
       "2021-04-30  40109      6.615873     12.437842\n",
       "2021-04-30  40143      7.372421     13.860151\n",
       "\n",
       "[189064 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wop = no2wop.groupby(['dates','fips']).agg({'rollMeanMean':'mean', 'rollMeanUgm3':'mean'})\n",
    "wop.reset_index().set_index('dates')\n",
    "# wop.index = pd.to_datetime(wop.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2wop.sort_values(by=['dates','fips'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0ad05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8c47058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_1\n",
       "71940     2020-01-01\n",
       "71941     2020-01-02\n",
       "71942     2020-01-03\n",
       "71943     2020-01-04\n",
       "71944     2020-01-05\n",
       "             ...    \n",
       "2046361   2021-10-11\n",
       "2046362   2021-10-12\n",
       "2046363   2021-10-13\n",
       "2046364   2021-10-14\n",
       "2046365   2021-10-15\n",
       "Name: dates, Length: 2038518, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pm25DF['Date of Last Change']\n",
    "anotherDF['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0961e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(anotherDF['dates'].dtype)\n",
    "print(airDF['Date of Last Change'].dtype)\n",
    "print(anotherDF['fips'].dtype)\n",
    "print(airDF['fips'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2414a1c",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4692ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportPbz2('covidPollutionCensus.pbz2',newDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fd3b6",
   "metadata": {},
   "source": [
    "And explore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(newDF.shape)\n",
    "# mask = newDF.isnull().any(axis=0)\n",
    "# noNullDF = newDF.loc[:,~mask]\n",
    "# print(noNullDF.shape)\n",
    "\n",
    "# newDF['density']=newDF['latestTotalPopulation']/newDF['LND110210']\n",
    "\n",
    "# # a = [x for x in newDF if x.startswith('ozone')]\n",
    "# b = [x for x in newDF if (x.startswith('JHU')|x.startswith('NYT'))&(~x.endswith('missing'))&('Confirmed' in x)]\n",
    "# # b.extend(a)\n",
    "# b\n",
    "# no2DF = newDF.loc[newDF['pollutant']=='no2',b+['Observation Count','Observation Percent','Arithmetic Mean',\\\n",
    "#                                                            '1st Max Value','Mean ugm3','fips','dates','density']]\n",
    "# # ozoneDF.dropna(subset=a,inplace=True)\n",
    "\n",
    "\n",
    "# # ozoneDF.dropna(subset=['Mean ugm3'],inplace=True)\n",
    "# no2fipsDF = no2DF[(no2DF['dates']>='2020-03-11')&(no2DF['dates']<='2021-03-11')].groupby(by=['fips']).agg({'JHU_ConfirmedDeaths.data': 'max', 'NYT_ConfirmedDeaths.data': 'max',\\\n",
    "#                               'Mean ugm3': 'mean','density': 'max'})\n",
    "\n",
    "# no2fipsDF.corr()\n",
    "\n",
    "# def covidPollutantFipsCorr(df, pollutant, cols=[]):\n",
    "#     if cols:\n",
    "#         polDF =  df.loc[df['pollutant']==pollutant,cols+['fips']]\n",
    "#     else:\n",
    "#         polDF = df.loc[df['pollutant']==pollutant,:]\n",
    "#     fipsDF  = polDF.groupby(by='fips').agg('mean')\n",
    "#     return fipsDF.corr()\n",
    "\n",
    "# dateFilterDF = newDF[(newDF['dates']>='2020-03-11')|(newDF['dates']<='2021-03-11')]\n",
    "\n",
    "# NO2\n",
    "\n",
    "# covidPollutantFipsCorr(dateFilterDF, 'no2', b[:5]+['Arithmetic Mean','density'])\n",
    "\n",
    "# Lead\n",
    "\n",
    "# covidPollutantFipsCorr(dateFilterDF, 'lead', b[:5]+['Arithmetic Mean','density'])\n",
    "\n",
    "# Ozone\n",
    "\n",
    "# covidPollutantFipsCorr(dateFilterDF, 'ozone', b[:5]+['Arithmetic Mean','density'])\n",
    "\n",
    "# PM2.5\n",
    "\n",
    "# covidPollutantFipsCorr(dateFilterDF, 'pm25', b[:5]+['Arithmetic Mean','density'])\n",
    "\n",
    "# a = no2fipsDF['Arithmetic Mean'].quantile([0,0.25,0.5,0.75,1])\n",
    "# b = no2fipsDF['JHU_ConfirmedDeaths.data'].quantile([0,0.25,0.5,0.75,1])\n",
    "\n",
    "# print(a)\n",
    "# print(b)\n",
    "\n",
    "# corrs =  newDF.corr()\n",
    "\n",
    "# numbDF = newDF.loc[:,newDF.dtypes!='object']\n",
    "# corrs = numbDF.corr()\n",
    "\n",
    "# # # newDF.to_csv('allTogetherNow.gz',index=False,compression='gzip')\n",
    "# # with bz2.BZ2File('allTogetherNow.pbz2','wb') as f:\n",
    "# #     pickle.dump(newDF,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
