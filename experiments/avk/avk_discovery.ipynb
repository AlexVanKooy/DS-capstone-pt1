{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d0698-a89c-4f60-8092-ad842f06b879",
   "metadata": {},
   "source": [
    "# Experiments Notebook 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe0588d-d9dc-4ea7-ae59-f515ba3bf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import bz2\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7de781-b19c-41f7-96d4-e7f620005fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kerashypetune import KerasGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8ecb2e-2eb5-42c2-87a3-d2550cbf7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d5bdbf-ae0b-453f-b529-7bf3223aeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce25521f-bad6-4705-b439-eda844e32615",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183fcd9-48c1-4e6d-a197-4c39853316c7",
   "metadata": {},
   "source": [
    "### Load the golden data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c511402-262c-45a0-a9ae-148b6802fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows version\n",
    "golden_dataset_file_name = os.path.join('..', '..', 'data', 'golden', 'feeFiFoFum.pbz2')\n",
    "\n",
    "# data = bz2.BZ2File(golden_dataset_file_name,'rb')\n",
    "with bz2.BZ2File(golden_dataset_file_name,'rb') as data:\n",
    "    df = pd.read_pickle(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fde0d-13e5-4198-9f8e-5689f1130301",
   "metadata": {},
   "source": [
    "### Clean up the data\n",
    "\n",
    "#### Drop non-numeric and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e761798-4dba-4c6c-96db-04ba85fb6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['NYT_ConfirmedCases.data','NYT_ConfirmedDeaths.data','NYT_ConfirmedDeaths.missing','county','LND110210','countyStateName','stateFip','countyFip']\n",
    "\n",
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cf9d9-f105-4376-80ce-65a15ad0bca0",
   "metadata": {},
   "source": [
    "#### Temporarily, replace FIPS codes with latitude and longitude of the centroid of each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e20f9-d1ca-4bfa-a76a-547209f8bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = pd.read_csv('../noah/2021_Gaz_counties_national.txt', delimiter='\\t')\n",
    "counties.rename(columns={'INTPTLONG                                                                                                               ': 'longitude',\n",
    "                        'INTPTLAT': 'latitude'}, inplace=True)\n",
    "# counties.columns = counties.columns.str.replace(\" \", \"\")\n",
    "\n",
    "counties = counties[['GEOID', 'latitude', 'longitude' ]]\n",
    "df.fips = df.fips.astype('int64')\n",
    "\n",
    "df = df.merge(counties, how='left', left_on='fips', right_on='GEOID')\n",
    "df.drop(['GEOID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324af6e-050d-4195-b5d9-4c9d51dac540",
   "metadata": {},
   "source": [
    "#### Replace dates with monotonically increasing integers starting with the minimum date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d464b3-5904-4671-9ef8-97b2450bfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dates = pd.to_datetime(df.dates, format='%Y-%m-%d')\n",
    "min_date = min(df.dates)\n",
    "max_date = max(df.dates)\n",
    "min_date, max_date, df.dates.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a52c51-f7f0-4835-a57e-8ec4298e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] =(df.dates - min_date).dt.days\n",
    "df.drop(['dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0581ee-2583-4748-8a3c-e4ccadc6a3ba",
   "metadata": {},
   "source": [
    "#### Replace the integer representation of date with sin and cosine encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517112d-13a1-4685-9f96-22e5ece969b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical_interval = 365\n",
    "continuous_interval = 3650\n",
    "df['cyclical_sin'] = np.sin((df.day * 2 * np.pi)/cyclical_interval)\n",
    "df['cyclical_cos'] = np.cos((df.day * 2 * np.pi)/cyclical_interval)\n",
    "df['continuous_sin'] = np.sin((df.day * 2 * np.pi)/continuous_interval)\n",
    "df['continuous_cos'] = np.cos((df.day * 2 * np.pi)/continuous_interval)\n",
    "df.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb951036-ea25-47cc-96c5-5a9b36527d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossed_latlong = pp.get_latlong_fc(df)\n",
    "\n",
    "lat_buckets = list(np.linspace(df.latitude.min(), df.latitude.max(),100))\n",
    "long_buckets = list(np.linspace(df.longitude.min(), df.longitude.max(),100))\n",
    "\n",
    "#make feature columns\n",
    "lat_fc = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'),lat_buckets)\n",
    "long_fc= tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),long_buckets)\n",
    "    \n",
    "# crossed columns tell the model how the features relate\n",
    "crossed_latlong = tf.feature_column.crossed_column(keys=[lat_fc, long_fc], hash_bucket_size=1000) # No precise rule, maybe 1000 buckets will be good?\n",
    "    \n",
    "embedded_latlong = tf.feature_column.embedding_column(crossed_latlong,9)\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(embedded_latlong)\n",
    "\n",
    "df[['geo0', 'geo1', 'geo2','geo3', 'geo4','geo5','geo6','geo7','geo8']] = feature_layer({'latitude': df.latitude, 'longitude': df.longitude})\n",
    "\n",
    "# df.drop(['longitude', 'latitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f842b-c049-404a-bb19-55f26e8efa25",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4739f-0f16-4480-b707-b86596004e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513da66f-15f7-4907-bf2d-f136a335f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = [\n",
    "       'TotalPopulation.data', 'MaleAndFemale_AtLeast65_Population.data',\n",
    "       'Male_Total_Population.data', 'Female_Total_Population.data',\n",
    "       'MaleAndFemale_Under18_Population.data', 'BLS_EmployedPopulation.data',\n",
    "       'BLS_EmployedPopulation.missing', 'BLS_UnemployedPopulation.data',\n",
    "       'BLS_UnemployedPopulation.missing', 'BLS_UnemploymentRate.data',\n",
    "       'BLS_UnemploymentRate.missing', 'BLS_LaborForcePopulation.data',\n",
    "       'BLS_LaborForcePopulation.missing', 'AverageDailyTemperature.data',\n",
    "       'AverageDailyTemperature.missing', 'AverageDewPoint.data',\n",
    "       'AverageDewPoint.missing', 'AverageRelativeHumidity.data',\n",
    "       'AverageRelativeHumidity.missing', 'AverageSurfaceAirPressure.data',\n",
    "       'AverageSurfaceAirPressure.missing', 'AveragePrecipitationTotal.data',\n",
    "       'AveragePrecipitationTotal.missing', 'AveragePrecipitation.data',\n",
    "       'AveragePrecipitation.missing', 'AverageWindDirection.data',\n",
    "       'AverageWindDirection.missing', 'AverageWindSpeed.data',\n",
    "       'AverageWindSpeed.missing', 'hospitalIcuBeds', 'hospitalStaffedBeds',\n",
    "       'hospitalLicensedBeds', 'latestTotalPopulation', 'jhu_daily_death',\n",
    "       'jhu_daily_cases', 'jhu_daily_new_cases', \n",
    "    'jhu_daily_death_rolling_7',\n",
    "       'jhu_daily_cases_rolling_7', 'jhu_daily_new_cases_rolling_7',\n",
    "       'jhu_daily_death_rolling_30', 'jhu_daily_cases_rolling_30',\n",
    "       'jhu_daily_new_cases_rolling_30', 'jhu_death_rate', 'jhu_case_rate',\n",
    "       'jhu_new_case_rate', 'density', 'icu_beds_per_person',\n",
    "       'staffed_beds_per_person', 'licensed_beds_per_person', 'cold_days',\n",
    "       'hot_days', 'moderate_days', 'gte_65_percent', 'lt_18_percent',\n",
    "       'employed_percent', 'unemployed_percent', 'totalMoved',\n",
    "       'movedWithinState', 'movedWithoutState', 'movedFromAbroad',\n",
    "       'publicTrans', 'totalTrans', 'householdsTotal', 'houseWith65',\n",
    "       'house2+with65', 'houseFamily65', 'houseNonfam65', 'houseNo65',\n",
    "       'house2+No65', 'houseFamilyNo65', 'houseNonfamNo65',\n",
    "       'householdStructuresTotal', 'householdIncomeMedian', 'gini',\n",
    "       'hoursWorkedMean', 'unitsInStructure', 'healthInsTotal',\n",
    "       'healthInsNativeWith', 'healthInsForeignNatWith',\n",
    "       'healthInsForeignNoncitWith', 'healthInsForeignNatNo',\n",
    "       'healthInsForeignNoncitNo', 'healthInsNativeNo', 'pm25']\n",
    "cols_raw = ['fips','JHU_ConfirmedCases.data', 'JHU_ConfirmedDeaths.data', 'cyclical_sin', 'cyclical_cos', 'continuous_sin',\n",
    "       'continuous_cos', 'latitude','longitude','geo0', 'geo1', 'geo2','geo3', 'geo4','geo5','geo6','geo7','geo8']\n",
    "df_normalized = df[cols_to_normalize]\n",
    "df_normalized = (df_normalized - df_normalized.mean())/df_normalized.std()\n",
    "df_raw = df[cols_raw]\n",
    "df = pd.concat([df_raw, df_normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bf3ef-a6d5-4f22-b336-f46f2798a363",
   "metadata": {},
   "source": [
    "#### Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a221d3e-7897-4f90-89bf-83ce8bc8fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7731216-cef5-4d0a-a9d2-51dfbe00172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_history = 30\n",
    "days_to_predict = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3c1f6-ec25-4420-8f70-b8d7f0cef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = df.fips.unique()\n",
    "\n",
    "def x_generator(data, days_of_history=30, days_to_predict=1):\n",
    "    for j, fip in enumerate(fips):\n",
    "        if not j % 100: print(j, end=' ')\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days_of_history, len(county) - days_to_predict):\n",
    "            data_matrix = data.iloc[i - days_of_history: i, 1:].to_numpy()\n",
    "            yield data_matrix\n",
    "            \n",
    "def y_generator(data, days_of_history=30, days_to_predict=1):\n",
    "    for fip in fips:\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days_of_history, len(county) - days_to_predict):\n",
    "            data_matrix = data.iloc[i: i + days_to_predict, 1:3].to_numpy()\n",
    "            yield data_matrix\n",
    "    \n",
    "def xy_generator(data, days=31):\n",
    "    for j, fip in enumerate(fips):\n",
    "        if not j % 100: print(j, end=' ')\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days, len(county) + 1):\n",
    "            data_matrix = data.iloc[i - days: i, 1:].to_numpy()\n",
    "            yield data_matrix\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac163c8-45f9-4a5c-972d-babb0d65816a",
   "metadata": {},
   "source": [
    "##### Save the raw X and Y to files of 50,000 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32add75b-d9ef-432b-a607-6fe85948c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = []\n",
    "j = 0\n",
    "\n",
    "N_SAMPLES = 200\n",
    "\n",
    "for i, x in tqdm(enumerate(xy_generator(df))):\n",
    "    Xi.append(x)\n",
    "    if i and not i % (N_SAMPLES - 1):\n",
    "        X = np.asarray(Xi)\n",
    "        np.save(os.path.join('.','data', f'x_{j}.npy'), X)\n",
    "        j += 1\n",
    "        Xi = []\n",
    "    \n",
    "if Xi:\n",
    "    X = np.asarray(Xi)\n",
    "    np.save(os.path.join('.','data', f'x_{j}.npy'), X)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664610a-0086-4410-b237-4ae731bce0d7",
   "metadata": {},
   "source": [
    "##### Split into train, test, eval directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54851ab5-4145-469a-b6c1-8de51fd9da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee865b7d-1f2b-4c1e-b24b-ee56a59ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_files = glob('./data/x_*.npy')\n",
    "random.shuffle(x_files)\n",
    "n_files = len(x_files)\n",
    "print(n_files)\n",
    "n_train = int(n_files * 0.70)\n",
    "print(n_train)\n",
    "n_eval = int(n_files * 0.15)\n",
    "print(n_eval)\n",
    "n_test = n_files - n_train - n_eval\n",
    "print(n_test)\n",
    "train_files = x_files[:n_train]\n",
    "# print(len(train_files))\n",
    "eval_files = x_files[n_train:n_train+n_test]\n",
    "# print(len(eval_files))\n",
    "test_files = x_files[n_train+n_test:]\n",
    "assert n_files == len(train_files) + len(eval_files) + len(test_files)\n",
    "for (subdir, lst) in [['train', train_files], ['eval', eval_files], ['test', test_files]]:\n",
    "    for file in lst:\n",
    "        shutil.move(file, os.path.join('.', 'data', subdir))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72038235-dbcf-47e3-8a70-7b8021b68f7f",
   "metadata": {},
   "source": [
    "##### Create the Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6ba81-7448-40c7-b5db-ae5382204a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= glob('*.png')\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c917f4-f604-48cf-a8dd-d07a1fffed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob('./data/train/x_*.npy')\n",
    "eval_files = glob('./data/eval/x_*.npy')\n",
    "test_files = glob('./data/test/x_*.npy')\n",
    "\n",
    "n_readers = 5\n",
    "n_parse_threads = 5\n",
    "len_array = 995\n",
    "\n",
    "def create_generator(files, cycle_length=5):\n",
    "    set_seed()\n",
    "    random.shuffle(files)\n",
    "    for i in range(0, len(files), cycle_length):\n",
    "        subset = files[i:i+cycle_length]\n",
    "        np_arrays = [np.load(s) for s in subset]\n",
    "        np_array = np.concatenate(np_arrays, axis=0)\n",
    "        # if np_array.shape[0] != len_array:\n",
    "        #     print('Oh no,', np_array.shape[0])\n",
    "        #     break\n",
    "        #     continue\n",
    "        np.random.shuffle(np_array)\n",
    "        yield np_array\n",
    "            \n",
    "\n",
    "def split_xy(np_array):\n",
    "    X = np_array[:,:-1,:]\n",
    "    y = np_array[:,-1:,:1]\n",
    "    return X,y\n",
    "        \n",
    "    \n",
    "train_ds = tf.data.Dataset.from_generator(lambda: create_generator(train_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "train_ds = train_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(lambda: create_generator(eval_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "val_ds = val_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(lambda: create_generator(test_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "test_ds = test_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e877a4-e55b-4c37-ad69-a333d01a0ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167ef76-baca-4faf-bc50-3e5975684d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaea1d7-a885-4ca5-9f52-83846c1bd2df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fc237f-ee3d-4cf1-a973-80a148f004db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_LAYER_TYPE=hp.HParam('layer_type', hp.Discrete(['keras.layers.LSTM', 'keras.layers.GRU']))\n",
    "HP_LAYER_TYPE=hp.HParam('layer_type', hp.Discrete(['keras.layers.LSTM']))\n",
    "HP_N_RECURRENT=hp.HParam('n_recurrent', hp.Discrete([2, 3, 4]))\n",
    "# HP_N_UNIT=hp.HParam('n_unit', hp.Discrete([32, 64, 128]))\n",
    "HP_N_UNIT=hp.HParam('n_unit', hp.Discrete([128]))\n",
    "HP_DROPOUT=hp.HParam('dropout', hp.Discrete([0.20]))\n",
    "HP_LR=hp.HParam('lr', hp.Discrete([1e-3]))\n",
    "METRIC_MAE = 'mae'\n",
    "\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_LAYER_TYPE, HP_N_RECURRENT, HP_N_UNIT, HP_DROPOUT, HP_LR],\n",
    "    metrics=[hp.Metric(METRIC_MAE, display_name='Mean Avg Error')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5a89db-7e16-4ae7-822d-94e790ca2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=65\n",
    "\n",
    "def train_test_model(hparams, shape=(30,101)):\n",
    "    set_seed()\n",
    "    input = keras.layers.Input(shape=shape)\n",
    "    last = input\n",
    "    for i in range(hparams[HP_N_RECURRENT]):\n",
    "        if i < hparams[HP_N_RECURRENT] - 1:\n",
    "            last = eval(hparams[HP_LAYER_TYPE])(hparams[HP_N_UNIT], return_sequences=True)(last)\n",
    "        else:\n",
    "            last = eval(hparams[HP_LAYER_TYPE])(hparams[HP_N_UNIT])(last)\n",
    "        \n",
    "        if hparams[HP_DROPOUT]:\n",
    "            last = keras.layers.Dropout(hparams[HP_DROPOUT])(last)\n",
    "\n",
    "        output = keras.layers.Dense(1)(last)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input, outputs=output)\n",
    "    model.compile(optimizer = Adam(learning_rate=hparams[HP_LR]),  loss='mae')\n",
    "    \n",
    "    model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS)\n",
    " \n",
    "    val_loss = model.evaluate(test_ds)\n",
    "    return val_loss\n",
    "        \n",
    "\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        val_loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MAE, val_loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a692d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9060dea1-612f-4b1c-af0f-987c0b70462c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'layer_type': 'keras.layers.LSTM', 'n_recurrent': 2, 'n_unit': 128, 'dropout': 0.2, 'lr': 0.001}\n",
      "Epoch 1/65\n",
      "1258/1258 [==============================] - 106s 83ms/step - loss: 1652.8772 - val_loss: 1584.4087\n",
      "Epoch 2/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 1519.7704 - val_loss: 1455.3624\n",
      "Epoch 3/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1397.6863 - val_loss: 1337.2169\n",
      "Epoch 4/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1286.0751 - val_loss: 1227.6377\n",
      "Epoch 5/65\n",
      "1258/1258 [==============================] - 117s 92ms/step - loss: 1181.3170 - val_loss: 1124.2870\n",
      "Epoch 6/65\n",
      "1258/1258 [==============================] - 119s 94ms/step - loss: 1084.8672 - val_loss: 1030.0352\n",
      "Epoch 7/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 995.1014 - val_loss: 942.3018\n",
      "Epoch 8/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 908.4341 - val_loss: 859.9958\n",
      "Epoch 9/65\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 826.2797 - val_loss: 776.0225\n",
      "Epoch 10/65\n",
      "1258/1258 [==============================] - 136s 108ms/step - loss: 748.0969 - val_loss: 700.5711\n",
      "Epoch 11/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 670.5472 - val_loss: 622.1948\n",
      "Epoch 12/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 593.4704 - val_loss: 544.4860\n",
      "Epoch 13/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 519.0111 - val_loss: 472.6204\n",
      "Epoch 14/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 446.9507 - val_loss: 399.0930\n",
      "Epoch 15/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 380.0994 - val_loss: 334.7058\n",
      "Epoch 16/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 320.6868 - val_loss: 276.4199\n",
      "Epoch 17/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 273.3894 - val_loss: 229.7476\n",
      "Epoch 18/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 246.4397 - val_loss: 207.6677\n",
      "Epoch 19/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 231.1541 - val_loss: 193.0017\n",
      "Epoch 20/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 213.3386 - val_loss: 170.6199\n",
      "Epoch 21/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 195.8313 - val_loss: 151.3855\n",
      "Epoch 22/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 178.5248 - val_loss: 134.7902\n",
      "Epoch 23/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 160.6699 - val_loss: 112.7899\n",
      "Epoch 24/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 142.4639 - val_loss: 99.4828\n",
      "Epoch 25/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 124.9820 - val_loss: 89.2130\n",
      "Epoch 26/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 108.0526 - val_loss: 65.1665\n",
      "Epoch 27/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 92.7146 - val_loss: 62.5521\n",
      "Epoch 28/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 82.8319 - val_loss: 36.4605\n",
      "Epoch 29/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 79.0072 - val_loss: 37.5275\n",
      "Epoch 30/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 75.0207 - val_loss: 26.6903\n",
      "Epoch 31/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.1084 - val_loss: 31.4366\n",
      "Epoch 32/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 73.8047 - val_loss: 45.3156\n",
      "Epoch 33/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 72.9553 - val_loss: 28.2994\n",
      "Epoch 34/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 72.7513 - val_loss: 24.3449\n",
      "Epoch 35/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 71.8532 - val_loss: 22.9522\n",
      "Epoch 36/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.4626 - val_loss: 39.3644\n",
      "Epoch 37/65\n",
      "1258/1258 [==============================] - 117s 93ms/step - loss: 69.1229 - val_loss: 24.3523\n",
      "Epoch 38/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.0644 - val_loss: 28.2564\n",
      "Epoch 39/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 68.7456 - val_loss: 21.0881\n",
      "Epoch 40/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.3579 - val_loss: 23.0514\n",
      "Epoch 41/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.1004 - val_loss: 23.6379\n",
      "Epoch 42/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 68.4844 - val_loss: 29.0443\n",
      "Epoch 43/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 68.5383 - val_loss: 16.9108\n",
      "Epoch 44/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 67.2857 - val_loss: 32.5522\n",
      "Epoch 45/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 68.0889 - val_loss: 36.1596\n",
      "Epoch 46/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 70.7768 - val_loss: 31.4169\n",
      "Epoch 47/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.6186 - val_loss: 37.0355\n",
      "Epoch 48/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 67.9737 - val_loss: 23.0471\n",
      "Epoch 49/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 67.9285 - val_loss: 35.9375\n",
      "Epoch 50/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 67.2151 - val_loss: 26.0249\n",
      "Epoch 51/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.6211 - val_loss: 32.3684\n",
      "Epoch 52/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 70.1797 - val_loss: 32.4059\n",
      "Epoch 53/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 66.3792 - val_loss: 32.4234\n",
      "Epoch 54/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 66.5381 - val_loss: 32.0931\n",
      "Epoch 55/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 66.4028 - val_loss: 28.0456\n",
      "Epoch 56/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 66.2215 - val_loss: 20.2068\n",
      "Epoch 57/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 66.0085 - val_loss: 30.6643\n",
      "Epoch 58/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 65.4438 - val_loss: 19.9241\n",
      "Epoch 59/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.4075 - val_loss: 25.1930\n",
      "Epoch 60/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 68.5421 - val_loss: 33.6004\n",
      "Epoch 61/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 67.2148 - val_loss: 31.5398\n",
      "Epoch 62/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 66.9579 - val_loss: 29.6866\n",
      "Epoch 63/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 68.5620 - val_loss: 48.3481\n",
      "Epoch 64/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.7887 - val_loss: 28.8319\n",
      "Epoch 65/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.1398 - val_loss: 70.8757\n",
      "270/270 [==============================] - 27s 101ms/step - loss: 71.4312\n",
      "--- Starting trial: run-1\n",
      "{'layer_type': 'keras.layers.LSTM', 'n_recurrent': 3, 'n_unit': 128, 'dropout': 0.2, 'lr': 0.001}\n",
      "Epoch 1/65\n",
      "1258/1258 [==============================] - 125s 97ms/step - loss: 1660.7112 - val_loss: 1591.8258\n",
      "Epoch 2/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1524.3895 - val_loss: 1458.5557\n",
      "Epoch 3/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1400.0536 - val_loss: 1339.1277\n",
      "Epoch 4/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1287.4960 - val_loss: 1228.2413\n",
      "Epoch 5/65\n",
      "1258/1258 [==============================] - 117s 92ms/step - loss: 1182.4110 - val_loss: 1125.3123\n",
      "Epoch 6/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1084.8375 - val_loss: 1029.8247\n",
      "Epoch 7/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 994.2657 - val_loss: 940.9329\n",
      "Epoch 8/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 116s 92ms/step - loss: 907.0857 - val_loss: 853.7101\n",
      "Epoch 9/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 824.5488 - val_loss: 775.6342\n",
      "Epoch 10/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 745.4536 - val_loss: 695.3893\n",
      "Epoch 11/65\n",
      "1258/1258 [==============================] - 117s 93ms/step - loss: 667.5104 - val_loss: 618.4983\n",
      "Epoch 12/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 591.4382 - val_loss: 543.3099\n",
      "Epoch 13/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 517.4125 - val_loss: 471.7239\n",
      "Epoch 14/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 445.3623 - val_loss: 401.9580\n",
      "Epoch 15/65\n",
      "1258/1258 [==============================] - 115s 90ms/step - loss: 378.8105 - val_loss: 335.8512\n",
      "Epoch 16/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 319.7679 - val_loss: 279.2834\n",
      "Epoch 17/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 273.4738 - val_loss: 240.5829\n",
      "Epoch 18/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 246.8681 - val_loss: 220.5737\n",
      "Epoch 19/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 233.5055 - val_loss: 193.2692\n",
      "Epoch 20/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 216.3655 - val_loss: 188.3592\n",
      "Epoch 21/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 198.7991 - val_loss: 184.2033\n",
      "Epoch 22/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 181.3163 - val_loss: 156.1797\n",
      "Epoch 23/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 163.2675 - val_loss: 145.0042\n",
      "Epoch 24/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 147.0266 - val_loss: 168.7256\n",
      "Epoch 25/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 129.7639 - val_loss: 109.1198\n",
      "Epoch 26/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 112.9966 - val_loss: 114.3214\n",
      "Epoch 27/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 97.9933 - val_loss: 74.4082\n",
      "Epoch 28/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 84.8247 - val_loss: 227.7551\n",
      "Epoch 29/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 79.1043 - val_loss: 168.6523\n",
      "Epoch 30/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 76.3995 - val_loss: 173.7006\n",
      "Epoch 31/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 75.9467 - val_loss: 206.1527\n",
      "Epoch 32/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.8550 - val_loss: 79.5232\n",
      "Epoch 33/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 75.9232 - val_loss: 67.1609\n",
      "Epoch 34/65\n",
      "1258/1258 [==============================] - 117s 93ms/step - loss: 75.3984 - val_loss: 209.2862\n",
      "Epoch 35/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 75.2206 - val_loss: 178.0952\n",
      "Epoch 36/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.7989 - val_loss: 191.1797\n",
      "Epoch 37/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 75.0833 - val_loss: 75.1937\n",
      "Epoch 38/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.8467 - val_loss: 68.5268\n",
      "Epoch 39/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 72.7543 - val_loss: 89.7421\n",
      "Epoch 40/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 72.1287 - val_loss: 183.5223\n",
      "Epoch 41/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 72.3616 - val_loss: 73.6607\n",
      "Epoch 42/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.6167 - val_loss: 75.0421\n",
      "Epoch 43/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.4396 - val_loss: 37.1727\n",
      "Epoch 44/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.3603 - val_loss: 80.8197\n",
      "Epoch 45/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.1227 - val_loss: 53.7009\n",
      "Epoch 46/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.0971 - val_loss: 68.4394\n",
      "Epoch 47/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.5754 - val_loss: 135.2427\n",
      "Epoch 48/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 70.9589 - val_loss: 69.0713\n",
      "Epoch 49/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 70.8912 - val_loss: 163.9666\n",
      "Epoch 50/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.8092 - val_loss: 141.7322\n",
      "Epoch 51/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 70.5732 - val_loss: 76.2299\n",
      "Epoch 52/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 70.7750 - val_loss: 53.8447\n",
      "Epoch 53/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 147.0896 - val_loss: 42.8885\n",
      "Epoch 54/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 77.0287 - val_loss: 38.7296\n",
      "Epoch 55/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.6191 - val_loss: 34.7688\n",
      "Epoch 56/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.4232 - val_loss: 40.9586\n",
      "Epoch 57/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.5085 - val_loss: 32.6528\n",
      "Epoch 58/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 73.8844 - val_loss: 30.5377\n",
      "Epoch 59/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 73.7272 - val_loss: 33.9640\n",
      "Epoch 60/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 73.3498 - val_loss: 30.6772\n",
      "Epoch 61/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 72.8353 - val_loss: 29.8198\n",
      "Epoch 62/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 74.0266 - val_loss: 27.8672\n",
      "Epoch 63/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.5299 - val_loss: 27.6977\n",
      "Epoch 64/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.2191 - val_loss: 24.6244\n",
      "Epoch 65/65\n",
      "1258/1258 [==============================] - 115s 91ms/step - loss: 71.0291 - val_loss: 23.9805\n",
      "270/270 [==============================] - 22s 81ms/step - loss: 24.6070\n",
      "--- Starting trial: run-2\n",
      "{'layer_type': 'keras.layers.LSTM', 'n_recurrent': 4, 'n_unit': 128, 'dropout': 0.2, 'lr': 0.001}\n",
      "Epoch 1/65\n",
      "1258/1258 [==============================] - 126s 97ms/step - loss: 1662.7625 - val_loss: 1608.4286\n",
      "Epoch 2/65\n",
      "1258/1258 [==============================] - 118s 93ms/step - loss: 1560.4056 - val_loss: 1510.8612\n",
      "Epoch 3/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1473.6077 - val_loss: 1432.2963\n",
      "Epoch 4/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1405.9247 - val_loss: 1369.8452\n",
      "Epoch 5/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1351.5293 - val_loss: 1318.5387\n",
      "Epoch 6/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 1308.2747 - val_loss: 1280.2501\n",
      "Epoch 7/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 1276.3336 - val_loss: 1252.2416\n",
      "Epoch 8/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 1128.4661 - val_loss: 1037.8202\n",
      "Epoch 9/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 1003.0644 - val_loss: 949.9950\n",
      "Epoch 10/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 922.9262 - val_loss: 873.0833\n",
      "Epoch 11/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 848.2406 - val_loss: 798.9545\n",
      "Epoch 12/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 772.8260 - val_loss: 717.0038\n",
      "Epoch 13/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 690.9437 - val_loss: 636.9153\n",
      "Epoch 14/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 609.8576 - val_loss: 563.1824\n",
      "Epoch 15/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 526.4737 - val_loss: 473.6361\n",
      "Epoch 16/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 116s 91ms/step - loss: 449.8980 - val_loss: 408.8066\n",
      "Epoch 17/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 384.6300 - val_loss: 343.5402\n",
      "Epoch 18/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 326.7970 - val_loss: 288.4184\n",
      "Epoch 19/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 279.6188 - val_loss: 240.5264\n",
      "Epoch 20/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 250.6174 - val_loss: 210.8206\n",
      "Epoch 21/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 234.9480 - val_loss: 203.3207\n",
      "Epoch 22/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 218.5208 - val_loss: 181.2148\n",
      "Epoch 23/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 197.6826 - val_loss: 170.6637\n",
      "Epoch 24/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 179.4939 - val_loss: 138.8883\n",
      "Epoch 25/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 161.5415 - val_loss: 126.1938\n",
      "Epoch 26/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 144.1317 - val_loss: 105.5656\n",
      "Epoch 27/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 128.7088 - val_loss: 86.6321\n",
      "Epoch 28/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 109.8011 - val_loss: 69.5173\n",
      "Epoch 29/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 92.4655 - val_loss: 62.1017\n",
      "Epoch 30/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 84.1207 - val_loss: 64.0355\n",
      "Epoch 31/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 77.5436 - val_loss: 47.4335\n",
      "Epoch 32/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 74.5910 - val_loss: 34.5041\n",
      "Epoch 33/65\n",
      "1258/1258 [==============================] - 118s 93ms/step - loss: 74.8842 - val_loss: 63.2024\n",
      "Epoch 34/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 74.3982 - val_loss: 46.3703\n",
      "Epoch 35/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 72.2636 - val_loss: 35.0570\n",
      "Epoch 36/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 74.1960 - val_loss: 38.3938\n",
      "Epoch 37/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 72.0121 - val_loss: 64.3754\n",
      "Epoch 38/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 98.5560 - val_loss: 100.2379\n",
      "Epoch 39/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 75.3225 - val_loss: 38.4620\n",
      "Epoch 40/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 79.7068 - val_loss: 52.3680\n",
      "Epoch 41/65\n",
      "1258/1258 [==============================] - 117s 93ms/step - loss: 80.5486 - val_loss: 56.4130\n",
      "Epoch 42/65\n",
      "1258/1258 [==============================] - 117s 92ms/step - loss: 81.7141 - val_loss: 77.0889\n",
      "Epoch 43/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 77.2446 - val_loss: 87.7523\n",
      "Epoch 44/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 77.8112 - val_loss: 79.5244\n",
      "Epoch 45/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 81.6614 - val_loss: 80.2186\n",
      "Epoch 46/65\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 79.2131 - val_loss: 63.0817\n",
      "Epoch 47/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 78.6803 - val_loss: 90.3634\n",
      "Epoch 48/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 76.5208 - val_loss: 97.1776\n",
      "Epoch 49/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 80.7495 - val_loss: 47.1037\n",
      "Epoch 50/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 85.2258 - val_loss: 74.2611\n",
      "Epoch 51/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 85.0384 - val_loss: 68.2306\n",
      "Epoch 52/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 79.8294 - val_loss: 53.3371\n",
      "Epoch 53/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 74.6553 - val_loss: 85.8470\n",
      "Epoch 54/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 72.4202 - val_loss: 58.4681\n",
      "Epoch 55/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 72.1409 - val_loss: 87.2603\n",
      "Epoch 56/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 71.0771 - val_loss: 57.9113\n",
      "Epoch 57/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 93.9537 - val_loss: 100.2962\n",
      "Epoch 58/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 98.3740 - val_loss: 39.7746\n",
      "Epoch 59/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 75.1955 - val_loss: 31.4828\n",
      "Epoch 60/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 70.5991 - val_loss: 31.5349\n",
      "Epoch 61/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 75.4109 - val_loss: 84.9167\n",
      "Epoch 62/65\n",
      "1258/1258 [==============================] - 119s 94ms/step - loss: 71.7902 - val_loss: 29.7184\n",
      "Epoch 63/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 85.8772 - val_loss: 57.6168\n",
      "Epoch 64/65\n",
      "1258/1258 [==============================] - 116s 92ms/step - loss: 69.5734 - val_loss: 34.4686\n",
      "Epoch 65/65\n",
      "1258/1258 [==============================] - 117s 92ms/step - loss: 70.8692 - val_loss: 40.9097\n",
      "270/270 [==============================] - 23s 83ms/step - loss: 41.9478\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for layer_type in HP_LAYER_TYPE.domain.values:\n",
    "    for n_recurrent in HP_N_RECURRENT.domain.values:\n",
    "        for n_unit in HP_N_UNIT.domain.values:\n",
    "            for dropout in HP_DROPOUT.domain.values:\n",
    "                for lr in HP_LR.domain.values:\n",
    "                    hparams = {\n",
    "                      HP_LAYER_TYPE: layer_type,\n",
    "                      HP_N_RECURRENT: n_recurrent,\n",
    "                      HP_N_UNIT: n_unit,\n",
    "                      HP_DROPOUT: dropout,\n",
    "                      HP_LR: lr\n",
    "                    }\n",
    "                    run_name = f'run-{session_num}'\n",
    "                    print(f'--- Starting trial: {run_name}')\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run(f'./logs/hparam_tuning/{run_name}', hparams)\n",
    "                    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26174f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capDL",
   "language": "python",
   "name": "capdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
