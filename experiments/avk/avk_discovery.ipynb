{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d0698-a89c-4f60-8092-ad842f06b879",
   "metadata": {},
   "source": [
    "# Experiments Notebook 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f293244-628b-4bee-a316-cf96b7b89bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import bz2\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kerashypetune import KerasGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8ecb2e-2eb5-42c2-87a3-d2550cbf7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d5bdbf-ae0b-453f-b529-7bf3223aeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce25521f-bad6-4705-b439-eda844e32615",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183fcd9-48c1-4e6d-a197-4c39853316c7",
   "metadata": {},
   "source": [
    "### Load the golden data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c511402-262c-45a0-a9ae-148b6802fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows version\n",
    "golden_dataset_file_name = os.path.join('..', '..', 'data', 'golden', 'feeFiFoFum.pbz2')\n",
    "\n",
    "# data = bz2.BZ2File(golden_dataset_file_name,'rb')\n",
    "with bz2.BZ2File(golden_dataset_file_name,'rb') as data:\n",
    "    df = pd.read_pickle(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fde0d-13e5-4198-9f8e-5689f1130301",
   "metadata": {},
   "source": [
    "### Clean up the data\n",
    "\n",
    "#### Drop non-numeric and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e761798-4dba-4c6c-96db-04ba85fb6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['NYT_ConfirmedCases.data','NYT_ConfirmedDeaths.data','NYT_ConfirmedDeaths.missing','county','LND110210','countyStateName','stateFip','countyFip']\n",
    "\n",
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cf9d9-f105-4376-80ce-65a15ad0bca0",
   "metadata": {},
   "source": [
    "#### Temporarily, replace FIPS codes with latitude and longitude of the centroid of each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128e20f9-d1ca-4bfa-a76a-547209f8bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = pd.read_csv('../noah/2021_Gaz_counties_national.txt', delimiter='\\t')\n",
    "counties.rename(columns={'INTPTLONG                                                                                                               ': 'longitude',\n",
    "                        'INTPTLAT': 'latitude'}, inplace=True)\n",
    "# counties.columns = counties.columns.str.replace(\" \", \"\")\n",
    "\n",
    "counties = counties[['GEOID', 'latitude', 'longitude' ]]\n",
    "df.fips = df.fips.astype('int64')\n",
    "\n",
    "df = df.merge(counties, how='left', left_on='fips', right_on='GEOID')\n",
    "df.drop(['GEOID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324af6e-050d-4195-b5d9-4c9d51dac540",
   "metadata": {},
   "source": [
    "#### Replace dates with monotonically increasing integers starting with the minimum date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d464b3-5904-4671-9ef8-97b2450bfc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-03-11 00:00:00'),\n",
       " Timestamp('2022-01-16 00:00:00'),\n",
       " dtype('<M8[ns]'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dates = pd.to_datetime(df.dates, format='%Y-%m-%d')\n",
    "min_date = min(df.dates)\n",
    "max_date = max(df.dates)\n",
    "min_date, max_date, df.dates.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a52c51-f7f0-4835-a57e-8ec4298e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] =(df.dates - min_date).dt.days\n",
    "df.drop(['dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0581ee-2583-4748-8a3c-e4ccadc6a3ba",
   "metadata": {},
   "source": [
    "#### Replace the integer representation of date with sin and cosine encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4517112d-13a1-4685-9f96-22e5ece969b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical_interval = 365\n",
    "continuous_interval = 3650\n",
    "df['cyclical_sin'] = np.sin((df.day * 2 * np.pi)/cyclical_interval)\n",
    "df['cyclical_cos'] = np.cos((df.day * 2 * np.pi)/cyclical_interval)\n",
    "df['continuous_sin'] = np.sin((df.day * 2 * np.pi)/continuous_interval)\n",
    "df['continuous_cos'] = np.cos((df.day * 2 * np.pi)/continuous_interval)\n",
    "df.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb951036-ea25-47cc-96c5-5a9b36527d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossed_latlong = pp.get_latlong_fc(df)\n",
    "\n",
    "lat_buckets = list(np.linspace(df.latitude.min(), df.latitude.max(),100))\n",
    "long_buckets = list(np.linspace(df.longitude.min(), df.longitude.max(),100))\n",
    "\n",
    "#make feature columns\n",
    "lat_fc = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'),lat_buckets)\n",
    "long_fc= tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),long_buckets)\n",
    "    \n",
    "# crossed columns tell the model how the features relate\n",
    "crossed_latlong = tf.feature_column.crossed_column(keys=[lat_fc, long_fc], hash_bucket_size=1000) # No precise rule, maybe 1000 buckets will be good?\n",
    "    \n",
    "embedded_latlong = tf.feature_column.embedding_column(crossed_latlong,9)\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(embedded_latlong)\n",
    "\n",
    "df[['geo0', 'geo1', 'geo2','geo3', 'geo4','geo5','geo6','geo7','geo8']] = feature_layer({'latitude': df.latitude, 'longitude': df.longitude})\n",
    "\n",
    "# df.drop(['longitude', 'latitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f842b-c049-404a-bb19-55f26e8efa25",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddd4739f-0f16-4480-b707-b86596004e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JHU_ConfirmedCases.data', 'JHU_ConfirmedDeaths.data',\n",
       "       'TotalPopulation.data', 'MaleAndFemale_AtLeast65_Population.data',\n",
       "       'Male_Total_Population.data', 'Female_Total_Population.data',\n",
       "       'MaleAndFemale_Under18_Population.data', 'BLS_EmployedPopulation.data',\n",
       "       'BLS_EmployedPopulation.missing', 'BLS_UnemployedPopulation.data',\n",
       "       ...\n",
       "       'continuous_cos', 'geo0', 'geo1', 'geo2', 'geo3', 'geo4', 'geo5',\n",
       "       'geo6', 'geo7', 'geo8'],\n",
       "      dtype='object', length=102)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "513da66f-15f7-4907-bf2d-f136a335f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = [\n",
    "       'TotalPopulation.data', 'MaleAndFemale_AtLeast65_Population.data',\n",
    "       'Male_Total_Population.data', 'Female_Total_Population.data',\n",
    "       'MaleAndFemale_Under18_Population.data', 'BLS_EmployedPopulation.data',\n",
    "       'BLS_EmployedPopulation.missing', 'BLS_UnemployedPopulation.data',\n",
    "       'BLS_UnemployedPopulation.missing', 'BLS_UnemploymentRate.data',\n",
    "       'BLS_UnemploymentRate.missing', 'BLS_LaborForcePopulation.data',\n",
    "       'BLS_LaborForcePopulation.missing', 'AverageDailyTemperature.data',\n",
    "       'AverageDailyTemperature.missing', 'AverageDewPoint.data',\n",
    "       'AverageDewPoint.missing', 'AverageRelativeHumidity.data',\n",
    "       'AverageRelativeHumidity.missing', 'AverageSurfaceAirPressure.data',\n",
    "       'AverageSurfaceAirPressure.missing', 'AveragePrecipitationTotal.data',\n",
    "       'AveragePrecipitationTotal.missing', 'AveragePrecipitation.data',\n",
    "       'AveragePrecipitation.missing', 'AverageWindDirection.data',\n",
    "       'AverageWindDirection.missing', 'AverageWindSpeed.data',\n",
    "       'AverageWindSpeed.missing', 'hospitalIcuBeds', 'hospitalStaffedBeds',\n",
    "       'hospitalLicensedBeds', 'latestTotalPopulation', 'jhu_daily_death',\n",
    "       'jhu_daily_cases', 'jhu_daily_new_cases', \n",
    "    'jhu_daily_death_rolling_7',\n",
    "       'jhu_daily_cases_rolling_7', 'jhu_daily_new_cases_rolling_7',\n",
    "       'jhu_daily_death_rolling_30', 'jhu_daily_cases_rolling_30',\n",
    "       'jhu_daily_new_cases_rolling_30', 'jhu_death_rate', 'jhu_case_rate',\n",
    "       'jhu_new_case_rate', 'density', 'icu_beds_per_person',\n",
    "       'staffed_beds_per_person', 'licensed_beds_per_person', 'cold_days',\n",
    "       'hot_days', 'moderate_days', 'gte_65_percent', 'lt_18_percent',\n",
    "       'employed_percent', 'unemployed_percent', 'totalMoved',\n",
    "       'movedWithinState', 'movedWithoutState', 'movedFromAbroad',\n",
    "       'publicTrans', 'totalTrans', 'householdsTotal', 'houseWith65',\n",
    "       'house2+with65', 'houseFamily65', 'houseNonfam65', 'houseNo65',\n",
    "       'house2+No65', 'houseFamilyNo65', 'houseNonfamNo65',\n",
    "       'householdStructuresTotal', 'householdIncomeMedian', 'gini',\n",
    "       'hoursWorkedMean', 'unitsInStructure', 'healthInsTotal',\n",
    "       'healthInsNativeWith', 'healthInsForeignNatWith',\n",
    "       'healthInsForeignNoncitWith', 'healthInsForeignNatNo',\n",
    "       'healthInsForeignNoncitNo', 'healthInsNativeNo', 'pm25']\n",
    "cols_raw = ['fips','JHU_ConfirmedCases.data', 'JHU_ConfirmedDeaths.data', 'cyclical_sin', 'cyclical_cos', 'continuous_sin',\n",
    "       'continuous_cos', 'latitude','longitude','geo0', 'geo1', 'geo2','geo3', 'geo4','geo5','geo6','geo7','geo8']\n",
    "df_normalized = df[cols_to_normalize]\n",
    "df_normalized = (df_normalized - df_normalized.mean())/df_normalized.std()\n",
    "df_raw = df[cols_raw]\n",
    "df = pd.concat([df_raw, df_normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bf3ef-a6d5-4f22-b336-f46f2798a363",
   "metadata": {},
   "source": [
    "#### Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a221d3e-7897-4f90-89bf-83ce8bc8fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1879589, 102)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7731216-cef5-4d0a-a9d2-51dfbe00172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_history = 30\n",
    "days_to_predict = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b3c1f6-ec25-4420-8f70-b8d7f0cef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = df.fips.unique()\n",
    "\n",
    "def x_generator(data, days_of_history=30, days_to_predict=1):\n",
    "    for j, fip in enumerate(fips):\n",
    "        if not j % 100: print(j, end=' ')\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days_of_history, len(county) - days_to_predict):\n",
    "            data_matrix = data.iloc[i - days_of_history: i, 1:].to_numpy()\n",
    "            yield data_matrix\n",
    "            \n",
    "def y_generator(data, days_of_history=30, days_to_predict=1):\n",
    "    for fip in fips:\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days_of_history, len(county) - days_to_predict):\n",
    "            data_matrix = data.iloc[i: i + days_to_predict, 1:3].to_numpy()\n",
    "            yield data_matrix\n",
    "    \n",
    "def xy_generator(data, days=31):\n",
    "    for j, fip in enumerate(fips):\n",
    "        if not j % 100: print(j, end=' ')\n",
    "        county = data[data.fips == fip]\n",
    "        for i in range(days, len(county) + 1):\n",
    "            data_matrix = data.iloc[i - days: i, 1:].to_numpy()\n",
    "            yield data_matrix\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac163c8-45f9-4a5c-972d-babb0d65816a",
   "metadata": {},
   "source": [
    "##### Save the raw X and Y to files of 50,000 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32add75b-d9ef-432b-a607-6fe85948c224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce29e8033a9042cba1b44f63df8e6460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 "
     ]
    }
   ],
   "source": [
    "Xi = []\n",
    "j = 0\n",
    "\n",
    "N_SAMPLES = 200\n",
    "\n",
    "for i, x in tqdm(enumerate(xy_generator(df))):\n",
    "    Xi.append(x)\n",
    "    if i and not i % (N_SAMPLES - 1):\n",
    "        X = np.asarray(Xi)\n",
    "        np.save(os.path.join('.','data', f'x_{j}.npy'), X)\n",
    "        j += 1\n",
    "        Xi = []\n",
    "    \n",
    "if Xi:\n",
    "    X = np.asarray(Xi)\n",
    "    np.save(os.path.join('.','data', f'x_{j}.npy'), X)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664610a-0086-4410-b237-4ae731bce0d7",
   "metadata": {},
   "source": [
    "##### Split into train, test, eval directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54851ab5-4145-469a-b6c1-8de51fd9da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee865b7d-1f2b-4c1e-b24b-ee56a59ca907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8981\n",
      "6286\n",
      "1347\n",
      "1348\n"
     ]
    }
   ],
   "source": [
    "x_files = glob('./data/x_*.npy')\n",
    "random.shuffle(x_files)\n",
    "n_files = len(x_files)\n",
    "print(n_files)\n",
    "n_train = int(n_files * 0.70)\n",
    "print(n_train)\n",
    "n_eval = int(n_files * 0.15)\n",
    "print(n_eval)\n",
    "n_test = n_files - n_train - n_eval\n",
    "print(n_test)\n",
    "train_files = x_files[:n_train]\n",
    "# print(len(train_files))\n",
    "eval_files = x_files[n_train:n_train+n_test]\n",
    "# print(len(eval_files))\n",
    "test_files = x_files[n_train+n_test:]\n",
    "assert n_files == len(train_files) + len(eval_files) + len(test_files)\n",
    "for (subdir, lst) in [['train', train_files], ['eval', eval_files], ['test', test_files]]:\n",
    "    for file in lst:\n",
    "        shutil.move(file, os.path.join('.', 'data', subdir))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72038235-dbcf-47e3-8a70-7b8021b68f7f",
   "metadata": {},
   "source": [
    "##### Create the Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7eb6ba81-7448-40c7-b5db-ae5382204a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= glob('*.png')\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72c917f4-f604-48cf-a8dd-d07a1fffed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob('./data/train/x_*.npy')\n",
    "eval_files = glob('./data/eval/x_*.npy')\n",
    "test_files = glob('./data/test/x_*.npy')\n",
    "\n",
    "n_readers = 5\n",
    "n_parse_threads = 5\n",
    "len_array = 995\n",
    "\n",
    "def create_generator(files, cycle_length=5):\n",
    "    set_seed()\n",
    "    random.shuffle(files)\n",
    "    for i in range(0, len(files), cycle_length):\n",
    "        subset = files[i:i+cycle_length]\n",
    "        np_arrays = [np.load(s) for s in subset]\n",
    "        np_array = np.concatenate(np_arrays, axis=0)\n",
    "        # if np_array.shape[0] != len_array:\n",
    "        #     print('Oh no,', np_array.shape[0])\n",
    "        #     break\n",
    "        #     continue\n",
    "        np.random.shuffle(np_array)\n",
    "        yield np_array\n",
    "            \n",
    "\n",
    "def split_xy(np_array):\n",
    "    X = np_array[:,:-1,:]\n",
    "    y = np_array[:,-1:,:1]\n",
    "    return X,y\n",
    "        \n",
    "    \n",
    "train_ds = tf.data.Dataset.from_generator(lambda: create_generator(train_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "train_ds = train_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(lambda: create_generator(eval_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "val_ds = val_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(lambda: create_generator(test_files, cycle_length=n_readers), output_types=tf.float32 )\n",
    "test_ds = test_ds.map(split_xy, num_parallel_calls=n_parse_threads).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e877a4-e55b-4c37-ad69-a333d01a0ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0167ef76-baca-4faf-bc50-3e5975684d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaea1d7-a885-4ca5-9f52-83846c1bd2df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4fc237f-ee3d-4cf1-a973-80a148f004db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_LAYER_TYPE=hp.HParam('layer_type', hp.Discrete(['keras.layers.LSTM', 'keras.layers.GRU']))\n",
    "HP_LAYER_TYPE=hp.HParam('layer_type', hp.Discrete(['keras.layers.LSTM']))\n",
    "HP_N_RECURRENT=hp.HParam('n_recurrent', hp.Discrete([2, 3, 4]))\n",
    "# HP_N_UNIT=hp.HParam('n_unit', hp.Discrete([32, 64, 128]))\n",
    "HP_N_UNIT=hp.HParam('n_unit', hp.Discrete([128]))\n",
    "HP_DROPOUT=hp.HParam('dropout', hp.Discrete([0.20]))\n",
    "HP_LR=hp.HParam('lr', hp.Discrete([1e-3]))\n",
    "METRIC_MAE = 'mae'\n",
    "\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_LAYER_TYPE, HP_N_RECURRENT, HP_N_UNIT, HP_DROPOUT, HP_LR],\n",
    "    metrics=[hp.Metric(METRIC_MAE, display_name='Mean Avg Error')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac5a89db-7e16-4ae7-822d-94e790ca2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=40\n",
    "\n",
    "def train_test_model(hparams, shape=(30,101)):\n",
    "    set_seed()\n",
    "    input = keras.layers.Input(shape=shape)\n",
    "    last = input\n",
    "    for i in range(hparams[HP_N_RECURRENT]):\n",
    "        if i < hparams[HP_N_RECURRENT] - 1:\n",
    "            last = eval(hparams[HP_LAYER_TYPE])(hparams[HP_N_UNIT], return_sequences=True)(last)\n",
    "        else:\n",
    "            last = eval(hparams[HP_LAYER_TYPE])(hparams[HP_N_UNIT])(last)\n",
    "        \n",
    "        if hparams[HP_DROPOUT]:\n",
    "            last = keras.layers.Dropout(hparams[HP_DROPOUT])(last)\n",
    "\n",
    "        output = keras.layers.Dense(1)(last)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input, outputs=output)\n",
    "    model.compile(optimizer = Adam(learning_rate=hparams[HP_LR]),  loss='mae')\n",
    "    \n",
    "    model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS)\n",
    " \n",
    "    val_loss = model.evaluate(test_ds)\n",
    "    return val_loss\n",
    "        \n",
    "\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        val_loss = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MAE, val_loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9060dea1-612f-4b1c-af0f-987c0b70462c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'layer_type': 'keras.layers.LSTM', 'n_recurrent': 2, 'n_unit': 128, 'dropout': 0.2, 'lr': 0.001}\n",
      "Epoch 1/40\n",
      "1258/1258 [==============================] - 116s 91ms/step - loss: 1652.8772 - val_loss: 1584.4087\n",
      "Epoch 2/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 1519.7765 - val_loss: 1455.3212\n",
      "Epoch 3/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 1397.6926 - val_loss: 1337.0518\n",
      "Epoch 4/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 1286.0759 - val_loss: 1227.4470\n",
      "Epoch 5/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 1181.2892 - val_loss: 1124.5208\n",
      "Epoch 6/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 1084.8680 - val_loss: 1030.0713\n",
      "Epoch 7/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 995.1063 - val_loss: 941.8906\n",
      "Epoch 8/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 908.5573 - val_loss: 863.1546\n",
      "Epoch 9/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 826.2388 - val_loss: 775.5337\n",
      "Epoch 10/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 748.0125 - val_loss: 699.5880\n",
      "Epoch 11/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 670.9449 - val_loss: 620.1067\n",
      "Epoch 12/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 594.9956 - val_loss: 546.9046\n",
      "Epoch 13/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 521.2301 - val_loss: 472.3742\n",
      "Epoch 14/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 449.8063 - val_loss: 401.8534\n",
      "Epoch 15/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 383.0496 - val_loss: 337.8424\n",
      "Epoch 16/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 323.7065 - val_loss: 280.1221\n",
      "Epoch 17/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 275.8315 - val_loss: 234.0930\n",
      "Epoch 18/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 247.5206 - val_loss: 206.4135\n",
      "Epoch 19/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 232.4707 - val_loss: 195.4200\n",
      "Epoch 20/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 215.2487 - val_loss: 170.8711\n",
      "Epoch 21/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 197.7477 - val_loss: 153.4682\n",
      "Epoch 22/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 180.3592 - val_loss: 134.3777\n",
      "Epoch 23/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 162.8063 - val_loss: 116.7980\n",
      "Epoch 24/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 144.9967 - val_loss: 99.2247\n",
      "Epoch 25/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 127.5029 - val_loss: 87.6467\n",
      "Epoch 26/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 109.5508 - val_loss: 76.6047\n",
      "Epoch 27/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 94.7696 - val_loss: 60.2032\n",
      "Epoch 28/40\n",
      "1258/1258 [==============================] - 122s 97ms/step - loss: 84.4433 - val_loss: 46.6293\n",
      "Epoch 29/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 80.4201 - val_loss: 36.8927\n",
      "Epoch 30/40\n",
      "1258/1258 [==============================] - 121s 95ms/step - loss: 75.6232 - val_loss: 32.4315\n",
      "Epoch 31/40\n",
      "1258/1258 [==============================] - 120s 95ms/step - loss: 75.3210 - val_loss: 31.6932\n",
      "Epoch 32/40\n",
      "1258/1258 [==============================] - 120s 95ms/step - loss: 73.7659 - val_loss: 24.4344\n",
      "Epoch 33/40\n",
      "1258/1258 [==============================] - 120s 95ms/step - loss: 72.2361 - val_loss: 28.7070\n",
      "Epoch 34/40\n",
      "1258/1258 [==============================] - 121s 96ms/step - loss: 73.5872 - val_loss: 28.7300\n",
      "Epoch 35/40\n",
      "1258/1258 [==============================] - 122s 96ms/step - loss: 72.4804 - val_loss: 23.2032\n",
      "Epoch 36/40\n",
      "1258/1258 [==============================] - 119s 94ms/step - loss: 72.2917 - val_loss: 32.5334\n",
      "Epoch 37/40\n",
      "1258/1258 [==============================] - 118s 94ms/step - loss: 71.7445 - val_loss: 33.5097\n",
      "Epoch 38/40\n",
      "1258/1258 [==============================] - 119s 94ms/step - loss: 72.7722 - val_loss: 27.8778\n",
      "Epoch 39/40\n",
      "1258/1258 [==============================] - 118s 94ms/step - loss: 71.6100 - val_loss: 22.0135\n",
      "Epoch 40/40\n",
      "1258/1258 [==============================] - 119s 94ms/step - loss: 75.4033 - val_loss: 54.9545\n",
      "270/270 [==============================] - 22s 82ms/step - loss: 56.0364\n",
      "--- Starting trial: run-1\n",
      "{'layer_type': 'keras.layers.LSTM', 'n_recurrent': 3, 'n_unit': 128, 'dropout': 0.2, 'lr': 0.001}\n",
      "Epoch 1/40\n",
      "     16/Unknown - 4s 92ms/step - loss: 1793.2670"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Starting trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m({h\u001b[38;5;241m.\u001b[39mname: hparams[h] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hparams})\n\u001b[1;32m---> 17\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs/hparam_tuning/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m session_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_dir, hparams)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcreate_file_writer(run_dir)\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     31\u001b[0m     hp\u001b[38;5;241m.\u001b[39mhparams(hparams)  \u001b[38;5;66;03m# record the values used in this trial\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mscalar(METRIC_MAE, val_loss, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[1;34m(hparams, shape)\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, outputs\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39mhparams[HP_LR]),  loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_loss\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mF:\\projects\\venvs\\capDL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for layer_type in HP_LAYER_TYPE.domain.values:\n",
    "    for n_recurrent in HP_N_RECURRENT.domain.values:\n",
    "        for n_unit in HP_N_UNIT.domain.values:\n",
    "            for dropout in HP_DROPOUT.domain.values:\n",
    "                for lr in HP_LR.domain.values:\n",
    "                    hparams = {\n",
    "                      HP_LAYER_TYPE: layer_type,\n",
    "                      HP_N_RECURRENT: n_recurrent,\n",
    "                      HP_N_UNIT: n_unit,\n",
    "                      HP_DROPOUT: dropout,\n",
    "                      HP_LR: lr\n",
    "                    }\n",
    "                    run_name = f'run-{session_num}'\n",
    "                    print(f'--- Starting trial: {run_name}')\n",
    "                    print({h.name: hparams[h] for h in hparams})\n",
    "                    run(f'./logs/hparam_tuning/{run_name}', hparams)\n",
    "                    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29b5bc-e01e-47d3-bc70-390852ad914f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capDL",
   "language": "python",
   "name": "capdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
